---
layout: article
tags: DeepLearning
description: Marchine Learning
---

### Logistic Regression

逻辑回归的假设函数：

$$h_{\theta}(x) =\frac{1}{1+e^{-\theta^{T}x}}$$

其中$x$是输入,$\theta$是要求解的参数。

函数图像：

![1555825110196](http://cdn.lisongqian.cn/1555825110196.png)

一个机器学习模型实际上是把决策函数限定在某组条件下，这组限定条件决定了模型的假设空间，逻辑回归的假设空间：

$$P(y=1|x;\theta)  = g(\theta^{T}x)=\frac{1}{1+e^{-\theta^{T}x}}$$

它的意思是在给定的$x$和$\theta$条件下,$y=1$的概率。

<!--more-->

### Support Vector Machine

直观理解：将数据点通过**某个函数**映射到**高维空间**中（我们称这个函数为**核函数**），这时寻找一个**平面**（我们称这个平面为**超平面**）对空间进行切分，达到同类的数据点在同一面的效果，最后将该平面与空间曲面形成的交线投影到原维度中，得到分类结果。

直观演示视频：[https://www.youtube.com/watch?v=3liCbRZPrZA]()

![img](http://cdn.lisongqian.cn/svm.gif)

> 不定期更新……