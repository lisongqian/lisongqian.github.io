<!--
	作者：Sariay
	时间：2018-08-26
	描述：There may be a bug, but don't worry, Qiling(器灵) says that it can work normally! aha!
-->
<!DOCTYPE html>
<html class="html-loading">
		

<head>
	<meta charset="utf-8">
  <meta name="referrer" content="no-referrer"/>
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
  <title>
    
      我发现了Transformer模型的秘密 | Songqian Li&#39;s Blog
    
  </title>
  <meta name="author" content="Songqian Li">
  <meta name="keywords" content="" />
  <meta name="description" content="enjoy life." />
	<!-- favicon -->
  <link rel="shortcut icon" href="/img/favicon.ico">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Playfair+Display:400,700,900">
  <!-- css -->
  
<link rel="stylesheet" href="/css/Annie.css">

  
  <!-- jquery -->
	
<script src="/plugin/jquery/jquery.min.js"></script>


<script>
    const CONFIG_BGIMAGE = {
      mode: 'normal',
      normalSrc: 'https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/header-bg.jpg',
      randomYouMax: 110,
      randomYouSrc: 'https://sariay.github.io/Random-img/',
	  randomOtherSrc: 'https://api.berryapi.net/?service=App.Bing.Images&day=-0',
	  preloaderEnable: false
    }
	
    const CONFIG_LEACLOUD_COUNT = {
      enable: true,
	  appId: 'L0W62cCkHAgT0VsIX6WztMhp-gzGzoHsz',
	  appKey: 'n1lX9eWfotXltQ6Cab3ngGfk',
	  serverURLs: 'https://l0w62cck.lc-cn-n1-shared.com' || ' '
    }
  </script>
<meta name="generator" content="Hexo 6.0.0"></head>
	<body>
		<!-- Preloader -->


<!-- header -->
<header class="fixbackground">
		<div class="header-wrapper">
		<ul id="global-nav">
	
		<li class="menu-home">
			<a href="/" class="menu-item-home" target="_blank">主页</a>
		</li>
		
	
		<li class="menu-archive">
			<a href="/archives" class="menu-item-archive" target="_blank">归档</a>
		</li>
		
	
		<li class="menu-categories">
			<a href="/categories" class="menu-item-categories" target="_blank">分类</a>
		</li>
		
	
		<li class="menu-tags">
			<a href="/tags" class="menu-item-tags" target="_blank">标签</a>
		</li>
		
	
		<li class="menu-about">
			<a href="/about" class="menu-item-about" target="_blank">关于</a>
		</li>
		
	

	
		<li class="menu-search">
			<a href="javascript:;" class="popup-trigger">搜索</a>
		</li>
	
</ul>
	</div>
	<div class="mask">
	<div class="banner-frame border-image" style="border-image-source: url('/img/mask.png');"></div>
		<div class="container">
			<div class="row">
				<div class="col-md-12">
					<div class="align">
						<h1 class="h1 light">Songqian Li&#39;s Blog</h1>
						<div class="empty-space col-xs-b15"></div>
						<div class="sa light large">enjoy life.</div>
						<div class="empty-space col-xs-b30"></div>
					</div>
				</div>
			</div>
		</div>
		<!-- motto -->
		<div class="h-body">	
			
		</div>
		
		<!-- others: such as time... -->			
		<div class="h-footer">
			<a href="javascript:;" id="read-more" class="scroll-down">
				<span class="icon-anchor1 animation-scroll-down"></span>
			</a>
		</div>
	</div>
</header>

<div id="navigation-hide">
	<!-- Progress bar -->
	<div id="progress-bar"></div>

	<!-- Progress percent -->
	<div id="progress-percentage"><span>0.0%</span></div>

	<div class="toc-switch"><span class="switch-button">目录</span></div>

	<!-- Page title -->
	<p>
		
			「我发现了Transformer模型的秘密」
		
	</p>

	
	

	<!-- Nav trigger for navigation-H-->
	<a class="nav-trigger"><span></span></a>
</div>

<!-- Navigation in div(id="navigation-H") -->
<nav class="nav-container" id="cd-nav">
	<div class="nav-header">
		<!--<span class="logo"> 
			<img src="/img/logo.png">
		</span> -->
		<a href="javascript:;" class="nav-close"></a>
	</div>
	
	<div class="nav-body">
		<ul id="global-nav">
	
		<li class="menu-home">
			<a href="/" class="menu-item-home" target="_blank">主页</a>
		</li>
		
	
		<li class="menu-archive">
			<a href="/archives" class="menu-item-archive" target="_blank">归档</a>
		</li>
		
	
		<li class="menu-categories">
			<a href="/categories" class="menu-item-categories" target="_blank">分类</a>
		</li>
		
	
		<li class="menu-tags">
			<a href="/tags" class="menu-item-tags" target="_blank">标签</a>
		</li>
		
	
		<li class="menu-about">
			<a href="/about" class="menu-item-about" target="_blank">关于</a>
		</li>
		
	

	
		<li class="menu-search">
			<a href="javascript:;" class="popup-trigger">搜索</a>
		</li>
	
</ul>
	</div>
	
	<div class="nav-footer">
		<ul id="global-social">
	
		<li>
			<a href="//github.com/lisongqian" target="_blank">
				<span class="icon-github"></span>
			</a>
		</li>
	
		<li>
			<a href="/atom.xml" target="_blank">
				<span class="icon-rss"></span>
			</a>
		</li>
			
</ul>

	</div>
</nav>
			
		<!--main-->
		<main>
			<!--
	时间：2018-11-17
	描述：
		插件名称：katelog.min.js
		插件作者：KELEN
		插件来源: https://github.com/KELEN/katelog
-->
	 

<div class="layout-post">
	<div id="layout-post">
		<div class="article-title">
			
	<a href="/2021/02/22/yuque/aih1sz/" itemprop="url">
		我发现了Transformer模型的秘密
	</a>

		</div>

		<div class="article-meta">
			<span>
				<i class="icon-calendar1"></i>
				
				




	更新于

	<a href="/2021/02/22/yuque/aih1sz/" itemprop="url">
		<time datetime="2021-02-22T08:06:27.000Z" itemprop="dateUpdated">
	  		2022-05-06
	  </time>
	</a> 



			</span>
			<span>
						
			</span>
			
			



		</div>

		<div class="article-content" id="article-content">
			<p>本文希望从 Base-Attention 到 Transformer 逐层递进的解释其中的计算细节,从而更好的理解 Transformer 模型。本文主要对模型可能存在的盲区进行解释，可能思路有些跳跃，请谅解。参考资料见文章末尾<code>Reference</code>.</p>
<h3 id="Base-Attention"><a href="#Base-Attention" class="headerlink" title="Base-Attention"></a>Base-Attention</h3><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412100228393.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191446-67eb1d4a-2bf5-43a1-ad9b-ca860f871f86.png#align=left&display=inline&height=337&margin=%5Bobject%20Object%5D&originHeight=337&originWidth=709&size=0&status=done&style=none&width=709"></a><br>如左图所示，为了实现<code>Attention</code>机制，我们需要一个 Z0Z0，与 h1h1 计算得到一个<code>scale</code>α10α01，这个 α10α01 可以简单看做 hh 与 zz 的相似度.<br>将 Z0Z0 与每一个 hihi 进行相乘然后 SoftmaxSoftmax 计算得到<code>distribution</code> αi0α0i，就变成了右图。这个<code>distribution</code>就是<code>Attention</code>机制的<code>Weight</code>。得到<code>Attention</code>之后将^αi0α^0i 乘上 hihi 后加到一起形成<code>Vector</code>C0C0，C0C0 就是预测第一个单词的特征向量。<br>注：本例中的<code>Value</code>是与<code>Key</code>相同的，但是实际上<code>Value</code>可以与<code>Key</code>不同，因为<code>Key</code>是用来计算<code>Attention</code>的<code>Weight</code>αα 的，而<code>Value</code>是用来与 αα 相乘得到<code>Vector</code>的，因此<code>Key</code>与<code>Value</code>不需要一定相同。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412140538223.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191409-c1a2c26f-0492-48c1-83ed-e5b13ea0fc08.png#align=left&display=inline&height=491&margin=%5Bobject%20Object%5D&originHeight=491&originWidth=777&size=0&status=done&style=none&width=777"></a><br><code>Dot-Product Attention</code>是 Base 的一种计算方式，图中表示了 Attention 的计算公式以及相对应的 Q,K,VQ,K,V 的维度。</p>
<h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h3><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412153633191.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191348-39d55af7-ac0e-4e08-a7bf-f13f5133af42.png#align=left&display=inline&height=813&margin=%5Bobject%20Object%5D&originHeight=813&originWidth=1429&size=0&status=done&style=none&width=1429"></a><br><code>Self-Attention</code>主要解决了训练时的并行问题，计算每个单词<code>Attention</code>时不用等前一个单词计算完成即可开始计算，以图中<code>a</code>为例。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412211908862.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191505-c0d8df7d-2e88-4774-85dd-43277d49ecfa.png#align=left&display=inline&height=745&margin=%5Bobject%20Object%5D&originHeight=745&originWidth=1263&size=0&status=done&style=none&width=1263"></a><br>如图以 e2e2 为例，把自身的<code>vector</code>作为<code>Query</code>，Dot-Product 的<code>Key</code>就是 e1e1。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200415141938375.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191415-c7c1a9c2-7f46-4faf-becc-3fb58b2680d3.png#align=left&display=inline&height=480&margin=%5Bobject%20Object%5D&originHeight=480&originWidth=818&size=0&status=done&style=none&width=818"></a><br>而在 decoder 的时候需要把 e2e2 后面的词给 mask 掉，因为<code>inference</code>阶段是没有后面输入。</p>
<h3 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h3><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200413154942609.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191498-39e92559-6df0-49be-8cc0-a0b758712b0f.png#align=left&display=inline&height=819&margin=%5Bobject%20Object%5D&originHeight=819&originWidth=1523&size=0&status=done&style=none&width=1523"></a><br>对<code>Multi-Head Attention</code>的相关解释如图所示。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200415143424126.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191416-b40d8540-979a-488a-9cd5-fb29b0b93734.png#align=left&display=inline&height=470&margin=%5Bobject%20Object%5D&originHeight=470&originWidth=946&size=0&status=done&style=none&width=946"></a><br><code>Scaled Dot-Product Attention</code>的<code>h</code>指的是<code>Multi-Head Attention</code>的数量。</p>
<h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412202544188.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191283-020828b2-a4c5-4bb8-8b82-c67e97aa4700.png#align=left&display=inline&height=787&margin=%5Bobject%20Object%5D&originHeight=787&originWidth=1203&size=0&status=done&style=none&width=1203"></a><br>Transformer 就是用 Self-Attention 替换了序列模型的 RNN 单元。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200413171304672.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191456-955a4543-3b44-4454-9a74-62a0caa31e5f.png#align=left&display=inline&height=808&margin=%5Bobject%20Object%5D&originHeight=808&originWidth=1536&size=0&status=done&style=none&width=1536"></a><br>本图主要解释了加入<code>Scaled</code>过程的原因，如上图中间的图像所示，蓝色是 QKTQKT，橙色是 softmax(QKT)softmax(QKT)，明显可以看出函数变的很尖，这样导致梯度变得很小，只有高数值的信息才会使模型更新，因此为了解决这个问题，在计算 softmax 之前除以 √dkdk。<br>这里可以理解为两个独立的矩阵，均值为 0，方差为 1。经过矩阵相乘之后，均值还是 0，方差会变成 dkdk，这样就会导致 Softmax 之后梯度变得很小。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200413180003131.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191232-6a6d2be0-4e0b-4f71-b201-3255af6d5801.png#align=left&display=inline&height=812&margin=%5Bobject%20Object%5D&originHeight=812&originWidth=1468&size=0&status=done&style=none&width=1468"></a><br>residual connection 是指经过一个 F(x)F(x)后，输出结果是 F(x)+xF(x)+x，这样做的目的是为了解决模型在多次进行 F(x)F(x)计算之后没有更多的<code>signore</code>的时候,模型可以弹性的选择哪部分要经过 F(x)F(x)，哪部分可以跳过 F(x)F(x)，而且模型也不需要更多的参数来进行训练。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200414151913660.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981192468-01860395-b3e6-4d10-a442-6b36575eeb33.png#align=left&display=inline&height=804&margin=%5Bobject%20Object%5D&originHeight=804&originWidth=1528&size=0&status=done&style=none&width=1528"></a><br>在<code>Decoder</code>中，因为序列的预测过程是从左往右，所以右面单词的<code>Attention</code>是未知的，这就是绿色框中<code>Masked</code>与红色框之间有区别的原因。<br>在蓝色框中，<code>Decoder</code>提供 Attention 的<code>Query</code>，<code>Encoder</code>提供 Attenion 的<code>Key</code>和<code>Query</code>。</p>
<h3 id="Training-Trick"><a href="#Training-Trick" class="headerlink" title="Training Trick"></a>Training Trick</h3><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200414164511250.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981192403-78e67c1e-c92b-425f-b2ad-c2fec0ea0713.png#align=left&display=inline&height=511&margin=%5Bobject%20Object%5D&originHeight=511&originWidth=1248&size=0&status=done&style=none&width=1248"></a></p>
<h4 id="Byte-pair-encodings"><a href="#Byte-pair-encodings" class="headerlink" title="Byte-pair encodings"></a>Byte-pair encodings</h4><p>BPE 算法的基本思路是把经常出现的<code>byte pair</code>用一个新的<code>byte</code>来代替，例如假设<code>(&#39;A&#39;, ’B‘）</code>经常顺序出现，则用一个新的标志<code>&#39;AB&#39;</code>来代替它们。<br>例如，假设我们的文本库中出现的单词及其出现次数为<code>&#123;&#39;l o w&#39;: 5, &#39;l o w e r&#39;: 2, &#39;n e w e s t&#39;: 6, &#39;w i d e s t&#39;: 3&#125;</code>，我们的初始词汇库为<code>&#123; &#39;l&#39;, &#39;o&#39;, &#39;w&#39;, &#39;e&#39;, &#39;r&#39;, &#39;n&#39;, &#39;w&#39;, &#39;s&#39;, &#39;t&#39;, &#39;i&#39;, &#39;d&#39;&#125;</code>，出现频率最高的 ngram pair 是<code>(&#39;e&#39;,&#39;s&#39;)</code> 9 次，所以我们将’es’作为新的词汇加入到词汇库中，由于’es’作为一个整体出现在词汇库中，这时文本库可表示为 <code>&#123;&#39;l o w&#39;: 5, &#39;l o w e r&#39;: 2, &#39;n e w es t&#39;: 6, &#39;w i d es t&#39;: 3&#125;</code>，这时出现频率最高的 ngram pair 是<code>(&#39;es&#39;,&#39;t&#39;)</code>9 次，将’est’加入到词汇库中，文本库更新为<code>&#123;&#39;l o w&#39;: 5, &#39;l o w e r&#39;: 2, &#39;n e w est&#39;: 6, &#39;w i d est&#39;: 3&#125;</code>，新的出现频率最高的 ngram pair 是(‘l’,’o’)7 次，将’lo’加入到词汇库中，文本库更新为<code>&#123;&#39;lo w&#39;: 5, &#39;lo w e r&#39;: 2, &#39;n e w est&#39;: 6, &#39;w i d est&#39;: 3&#125;</code>。以此类推，直到词汇库大小达到我们所设定的目标。这个例子中词汇量较小，对于词汇量很大的实际情况，我们就可以通过 BPE 逐步建造一个较小的基于 subword unit 的词汇库来表示所有的词汇。</p>
<h4 id="Checkpoint-averaging"><a href="#Checkpoint-averaging" class="headerlink" title="Checkpoint averaging"></a>Checkpoint averaging</h4><p>对训练过程中 checkpoint 保存的模型进行参数平均</p>
<h4 id="Boom-Search："><a href="#Boom-Search：" class="headerlink" title="Boom Search："></a>Boom Search：</h4><ol>
<li><code>step 1</code>：在预测第一个单词的时候选择前<code>Beam width</code>个概率最大的单词作为第一个单词；</li>
<li><code>step 2</code>：假设词汇表长<code>10000</code>,<code>B=3</code>按照 P(y&lt;1&gt;,y&lt;2&gt;|x)&#x3D;P(y&lt;1&gt;|x)P(y&lt;2&gt;|x,y&lt;1&gt;)P(y&lt;1&gt;,y&lt;2&gt;|x)&#x3D;P(y&lt;1&gt;|x)P(y&lt;2&gt;|x,y&lt;1&gt;)最大，就会在开头为(y&lt;1&gt;,y&lt;2&gt;)(y&lt;1&gt;,y&lt;2&gt;)的<code>30000</code>种选择中选取概率最大的<code>3</code>种，并将(y&lt;1&gt;,y&lt;2&gt;)(y&lt;1&gt;,y&lt;2&gt;)作为新的开头；</li>
<li><code>step 3</code>：将<code>step 2</code>中选取的新的开头作为条件,重复计算<code>step 2</code>，如果遇到终止符则停止。</li>
</ol>
<p>改进集束搜索（改进其打分规则）：<br>由于$\displaystyle argmax \prod_{t&#x3D;1}^{T_y}P(y^{}|x,y^{1},\dots,y^{t-1})$，是多个小于 1 的概率相乘，最终得到的数值会很小很小，出现数值下溢，因此对上述公式取对数：<br>argmaxTy∑t&#x3D;1log,P(y|x,y1,…,yt−1)argmax∑t&#x3D;1Tylog,P(y|x,y1,…,yt−1)<br>但是 log 函数在(0,1)是负数，序列越长数值越低，所以模型会更倾向于短文本输出而不是简洁的文本。于是第二次改进：<br>1TαyTy∑t&#x3D;1log,P(y|x,y1,…,yt−1)1Tyα∑t&#x3D;1Tylog,P(y|x,y1,…,yt−1)<br>对和函数进行归一化，但是不是单纯的除以单词数量，而是除以 TyTy 的 αα 次幂，这里的 αα 是一个超参数。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV19g4y1b7vx?p=1">台大《应用深度学习》国语课程(2020) by 陈蕴侬</a></li>
<li><a target="_blank" rel="noopener" href="https://mooc.study.163.com/course/2001280005#/info">序列模型 by Andrew Ng</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/69414965">CS224N 笔记(十二):Subword 模型</a></li>
</ol>
	
		</div>
		
		<div id="current-post-cover" data-scr="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg"></div>

		<!-- relate post, comment...-->
		<div class="investment-container">
			<div class="investment-header">
				<div class="investment-title-1">
					<div class="on">相关文章</div>
					<div>评论</div>
					<div>分享</div>
				</div>
				<div class="investment-title-2">	            
					
	<span>
		<a id="totop-post-page">返回顶部</a>
		
			<a href="/2021/02/22/yuque/ecdpur/" title="你看不懂的BERT解读" rel="prev">
				&laquo;上一篇
			</a>
		
		
			<a href="/2021/01/28/yuque/xnw3ik/" title="Chrome自动将http切换为https" rel="next">
				下一篇&raquo;
			</a>
			
	</span>


      		
				</div>	
			</div>
			
			<div class="investment-content">
				<div class="investment-content-list">
					

<div class="relate-post">
	
		<ul>
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/05/05/yuque/to6mm2/" title="为什么Proactor比Reactor模式更优？">
								为什么Proactor比Reactor模式更优？			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								五月 5日, 2022				
							</p>
							<p class="relate-post-content">
								首先，我们先了解一下什么是 Reactor 模式和 Proactor 模式。
什么是 Reactor 模式和 Proactor 模式？Reactor 模式Reactor 模式是指主线程负责监听和分发事件，工作线程负责 I&#x2F;O...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/05/05/yuque/to6mm2/" title="为什么Proactor比Reactor模式更优？">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="为什么Proactor比Reactor模式更优？"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/04/20/yuque/iki4ug/" title="每周阅读推荐">
								每周阅读推荐			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								四月 20日, 2022				
							</p>
							<p class="relate-post-content">
								
怎样设计出一个让面试官满意的架构

扩展视野，作者介绍了从一百个到千万级并发情况下服务端架构的演进过程，同时列举出每个演进阶段会遇到的相关技术，让读者可以对架构的演进有一个整体的认知。

《Effective C++》笔记 - 条款...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/04/20/yuque/iki4ug/" title="每周阅读推荐">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="每周阅读推荐"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/02/11/yuque/hlgqdt/" title="[转]你想住在中国哪里？">
								[转]你想住在中国哪里？			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								二月 11日, 2022				
							</p>
							<p class="relate-post-content">
								
科技爱好者周刊（第 180 期）：你想住在中国哪里？


如果希望赚取高收入，愿意忍受大城市的高竞争、高压力、狭小嘈杂，那么选择一线大城市；
如果希望竞争小一些、生活轻松一点，可以选择沿海省份和中西部的中心城市；
如果希望享受宁静悠...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/02/11/yuque/hlgqdt/" title="[转]你想住在中国哪里？">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="[转]你想住在中国哪里？"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/02/09/yuque/ga3q0g/" title="滑坡谬误">
								滑坡谬误			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								二月 9日, 2022				
							</p>
							<p class="relate-post-content">
								滑坡谬误（Slippery slope）指的是使用一连串的因果推论，夸大了每个环节的因果强度，而得到不合理的结论。它的典型形式是，“如果发生 A1，接着就会发生 A2，接着就会发生 A3，接着就会发生 A4，……，接着就会发生 An”...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/02/09/yuque/ga3q0g/" title="滑坡谬误">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="滑坡谬误"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/02/09/yuque/ccic59/" title="[转]你的HDMI2.1设备是真的HDMI 2.1吗？">
								[转]你的HDMI2.1设备是真的HDMI 2.1吗？			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								二月 9日, 2022				
							</p>
							<p class="relate-post-content">
								HDMI 许可管理员：

HDMI 2.0 不再存在，设备不应声称符合 v2.0，因为它不再被引用HDMI 2.0 的功能现在是 2.1 的子集与 HDMI 2.1 相关的所有新功能和特性都是可选的（包括 FRL、更高带宽、VRR、A...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/02/09/yuque/ccic59/" title="[转]你的HDMI2.1设备是真的HDMI 2.1吗？">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="[转]你的HDMI2.1设备是真的HDMI 2.1吗？"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/02/06/yuque/eizdmx/" title="语雀文档自动同步到hexo博客">
								语雀文档自动同步到hexo博客			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								二月 6日, 2022				
							</p>
							<p class="relate-post-content">
								前提阅读本文之前，需要已经正常搭建好 hexo 博客和语雀账号。同时我们需要准备：

一个 GitHub 账号
一个腾讯云账号
hexo 安装了 yuque-hexo 插件且能正常运行

实现思路：利用语雀的webhook触发腾讯云云...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/02/06/yuque/eizdmx/" title="语雀文档自动同步到hexo博客">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="语雀文档自动同步到hexo博客"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2021/04/28/yuque/fmkq8s/" title="Scriptable 小组件分享">
								Scriptable 小组件分享			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								四月 28日, 2021				
							</p>
							<p class="relate-post-content">
								https://github.com/lisongqian/Scriptable(GitHub 会一直更新，无法访问 GitHub 的话可以用文章末尾的百度网盘链接）
2022-01-20 更新
百度网盘文件已更新，目前支持 2022...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2021/04/28/yuque/fmkq8s/" title="Scriptable 小组件分享">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="Scriptable 小组件分享"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2021/03/17/yuque/tu1bg6/" title="容易忽视的C++知识">
								容易忽视的C++知识			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								三月 17日, 2021				
							</p>
							<p class="relate-post-content">
								格式化输出的执行顺序由于 C 语言参数压栈顺序是从右往左，所以 printf 和 cout 函数在执行时是从右往左读入缓冲区，然后从左往右输出。
右值引用和左值引用
C++一共有三种基本值类型: 左值(lvalue), 纯右值(prv...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2021/03/17/yuque/tu1bg6/" title="容易忽视的C++知识">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="容易忽视的C++知识"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2021/02/22/yuque/gvdw6p/" title="不知道这些知识还敢说自己做过前端？">
								不知道这些知识还敢说自己做过前端？			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								二月 22日, 2021				
							</p>
							<p class="relate-post-content">
								PromisePromise 最大的好处是在异步执行的流程中，把执行代码和处理结果的代码清晰地分离了
123456789101112131415new Promise((resolve, reject) =&gt; &#123;  c...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2021/02/22/yuque/gvdw6p/" title="不知道这些知识还敢说自己做过前端？">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="不知道这些知识还敢说自己做过前端？"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2021/02/22/yuque/qsv094/" title="使用PyTorch可视化必须知道的TensorBoard参数">
								使用PyTorch可视化必须知道的TensorBoard参数			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								二月 22日, 2021				
							</p>
							<p class="relate-post-content">
								亲测可用的PyTorch和TensorflowBoard版本，不会出现绘制模型结构图片时空白的情况。
1234torch==1.2.0tensorboard==2.1.1tensorflow==2.1.0tensorboardX==2...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2021/02/22/yuque/qsv094/" title="使用PyTorch可视化必须知道的TensorBoard参数">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="使用PyTorch可视化必须知道的TensorBoard参数"/>
							</a>
						</div>
					</li>												
			
		</ul>
	
</div>	
				</div>
				<div class="investment-content-list">
					<div class="layout-comment">

	

		

			<!-- gitalk comment -->
			<!-- show gitalk comment -->
<div id="gitalk-container"></div>

<!-- gitalk`s css & js -->
<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<link rel="stylesheet" href="/css/comment.css">
<script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<script type="text/javascript">

	(function gitalkComment(){
		//Thanks O-R
		//https://github.com/gitalk/gitalk/issues/102#issuecomment-382970552
		//去除尾部匹配正则数组的字符串  
		//Remove redundant characters
		String.prototype.trimEnd = function(regStr) {
			let result = this;
			if(regStr == undefined || regStr == null || regStr == "") {
				return result;
			}
			let array = regStr.split(',');

			if(array.length > 0) {

				let c = array.shift(), 
					str = this,
					i = str.length,
					rg = new RegExp(c),
					matchArr = str.match(rg);

				if(matchArr != undefined && matchArr != null && matchArr.length > 0) {
					let matchStr = matchArr[0].replace(/\\/g, "\\\\").replace(/\*/g, "\\*")
						.replace(/\+/g, "\\+").replace(/\|/g, "\\|")
						.replace(/\{/g, "\\{").replace(/\}/g, "\\}")
						.replace(/\(/g, "\\(").replace(/\)/g, "\\)")
						.replace(/\^/g, "\\^").replace(/\$/g, "\\$")
						.replace(/\[/g, "\\[").replace(/\]/g, "\\]")
						.replace(/\?/g, "\\?").replace(/\,/g, "\\,")
						.replace(/\./g, "\\.").replace(/\&/g, "\\&");
					matchStr = matchStr + '$';
					result = str.replace(new RegExp(matchStr), "");
				}

				if(array.length > 0) {
					return result.trimEnd(array.join())
				} else {
					return result;
				}
			}
		};

		//Create gitalk
		let gitalk = new Gitalk({
			clientID: '693063c1941dbc1701d3',
			clientSecret: 'f88ddf502ef33ce91ce9d8c140dbc7e3a0653b7e',
			//id: window.location.pathname,
			//id: decodeURI(window.location.pathname),
			//id: (window.location.pathname).split("/").pop().substring(0, 49),
			id: decodeURI( md5( location.href.trimEnd('#.*$,\\?.*$,index.html$') ) ),
			repo: 'lisongqian.github.io',
			owner: 'lisongqian',
			admin: 'lisongqian',
			distractionFreeMode: 'false',
		})
		gitalk.render('gitalk-container');		
	})();
</script>

		
		
	

</div>
				</div>
				<div class="investment-content-list">
					<div class="layout-share">
	
	

		
			
			<!-- socialShare share -->
			<div class="social-share"></div>

<!--  css & js -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>
			
		
		
	
</div>


				</div>
			</div>	
		</div>
	</div>
</div>

<!-- show math formula -->



	





<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">


<script src="/plugin/fancybox/jquery.fancybox.js"></script>


<script type="text/javascript">
	(function gallerySet(){
		let titleID = $('.article-title a'),
			imageID = $('.article-content img'),
			videoID = $('.article-content video');
		
		let postTitle = titleID.text() ? titleID.text() : "No post title!";
		
		imageID.each(function() {
			let imgPath = $(this).attr('src'),
				imgTitle = $(this).attr('alt') ? $(this).attr('alt') : "No image description!";
		
			//给每个匹配的<img>元素打包, 即添加父元素<a>
			$(this).wrap('<a data-fancybox="gallery" data-caption="《 ' + postTitle + ' 》' + imgTitle + '"href="' + imgPath + '"> </a>');
		});
		
		videoID.each(function() {
			let videoPath = $(this).attr('src');
		
			//给每个匹配的<img>元素打包, 即添加父元素<a>
			$(this).wrap('<a data-fancybox href=" ' + videoPath + ' "> </a>');
		});
		
		//TODO：支持html5 video

		if($('#layout-post').length) {
			$('[data-fancybox="gallery"]').fancybox({
				loop: true,
				buttons: [
					"zoom",
					"share",
					"slideShow",
					"fullScreen",
					//"download",
					"thumbs",
					"close"
				],
				protect: true
			});
		}
	})();
</script>
		</main>

		<!--footer-->
		<footer>
	<div id="navigation-show">
		<ul id="global-nav">
	
		<li class="menu-home">
			<a href="/" class="menu-item-home" target="_blank">主页</a>
		</li>
		
	
		<li class="menu-archive">
			<a href="/archives" class="menu-item-archive" target="_blank">归档</a>
		</li>
		
	
		<li class="menu-categories">
			<a href="/categories" class="menu-item-categories" target="_blank">分类</a>
		</li>
		
	
		<li class="menu-tags">
			<a href="/tags" class="menu-item-tags" target="_blank">标签</a>
		</li>
		
	
		<li class="menu-about">
			<a href="/about" class="menu-item-about" target="_blank">关于</a>
		</li>
		
	

	
		<li class="menu-search">
			<a href="javascript:;" class="popup-trigger">搜索</a>
		</li>
	
</ul>
	</div>

	<div class="copyright">
		<p>
		<a href="http://www.beian.miit.gov.cn/" target="_blank" rel="noopener">鲁ICP备16042410号</a>
			 
				&copy;2017 - 2022, content by SongqianLi. All Rights Reserved.
			
			
				<a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> Theme <a href="https://github.com/Sariay/hexo-theme-Annie" title="Annie" target="_blank" rel="noopener">Annie</a> by Sariay.
			
		</p>
		<p>
			

	<!-- busuanzi -->
	<!-- busuanzi -->



			<a href="javascript:zh_tran('s');" class="zh_click" id="zh_click_s">简体</a> 
			<a href="javascript:zh_tran('t');" class="zh_click" id="zh_click_t">繁體</a>				
		</p>
	</div>		
</footer>
		

<!-- love effect -->


<!-- back to top -->

	<div id="totop">
	<span class="icon-circle-up"></span>
</div>



<!-- site analysis -->


	<!-- site-analysis -->
	
	
	
	
	
 

<!-- leancloud -->


	<!-- leancloud -->
	<!--
	时间：2018-11-27
	描述：
		文章访问量：visitors
		文章喜欢量：likes	
		文章排行榜：topNPost
		其他得说明：
			01-Cookie相关的函数 
				https://blog.csdn.net/somehow1002/article/details/78511541（Author：somehow1002）
			02-visitors相关的函数 
				https://blog.csdn.net/u013553529/article/details/63357382（Author：爱博客大伯）
				https://notes.doublemine.me/2015-10-21-为NexT主题添加文章阅读量统计功能.html（Author：夏末）
			03-topNPost相关的函数
				https://hoxis.github.io/hexo-next-read-rank.html（Author：hoxis）
			04-likes相关的函数，
				参考了01 & 02进行简单的设计与实现
-->


  
<script src="/plugin/leancloud/av-min.js"></script>
<script src="/js/leancloud-count.js"></script>


	

  

	<!--
	时间：2018-10-3
	描述：
		插件名称：hexo-generator-search-zip
		插件来源: https://github.com/SuperKieran/hexo-generator-search-zip
		代码参考：https://github.com/SuperKieran/TKL/blob/master/layout/_partial/search.ejs(Include: js & css)	
-->
<div class="popup search-popup local-search-popup scrollbar" >
	<div class="local-search-container">
		<span class="popup-btn-close">
      		ESC
   		</span>
		<div class="local-search-header">
			<div class="input-prompt">				
			</div>
			<input autocomplete="off" placeholder="Search..." type="text" id="local-search-input">
		</div>
		<div class="local-search-body">
			<div id="local-search-output"></div>
		</div>
		<div class="local-search-footer">
			<div class="topN-post">				
				

   
	<div id="topN">
		<div class="topN-title" data-title= "热门文章"></div> 
	</div>
	
    <script>
        var limitCount = 10;
        if( $('#topN').length ){
            setTimeout(function() {
                topNPost(limitCount);
			}, 3000);
        }
    </script>
   
								
			</div>
		</div>
	</div>
</div>


<script src="/plugin/search/ziploader.js"></script>
<script src="/js/search.js"></script>


<script type="text/javascript">
	var search_path = 'search.json',
		zip_Path = '/search.zip',
		version_Path = '/searchVersion.txt',
		input_Trigger = 'auto',
		top_N = '2';

	themeLocalSearch({
		search_path, 
		zip_Path, 
		version_Path, 
		input_Trigger, 
		top_N
	});
</script>



<script src="/plugin/chinese/chinese.js"></script>
<script src="/plugin/imagelazyloader/yall.min.js"></script>
<script src="/plugin/imageloaded/imagesloaded.pkgd.min.js"></script>
<script src="/plugin/resizediv/resizediv.js"></script>
<script src="/js/main.js"></script>

	</body>	
</html>