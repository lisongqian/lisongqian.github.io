<!--
	作者：Sariay
	时间：2018-08-26
	描述：There may be a bug, but don't worry, Qiling(器灵) says that it can work normally! aha!
-->
<!DOCTYPE html>
<html class="html-loading">
		

<head>
	<meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
  <title>
    
      我发现了Transformer模型的秘密 | Songqian Li&#39;s Blog
    
  </title>
  <meta name="author" content="Songqian Li">
  <meta name="keywords" content="" />
  <meta name="description" content="C U" />
	<!-- favicon -->
  <link rel="shortcut icon" href="/img/favicon.ico">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Playfair+Display:400,700,900">
  <!-- css -->
  
<link rel="stylesheet" href="/css/Annie.css">

  
  <!-- jquery -->
	
<script src="/plugin/jquery/jquery.min.js"></script>


<script>
    const CONFIG_BGIMAGE = {
      mode: 'normal',
      normalSrc: 'https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/header-bg.jpg',
      randomYouMax: 110,
      randomYouSrc: 'https://sariay.github.io/Random-img/',
	  randomOtherSrc: 'https://api.berryapi.net/?service=App.Bing.Images&day=-0',
	  preloaderEnable: false
    }
	
    const CONFIG_LEACLOUD_COUNT = {
      enable: true,
	  appId: 'L0W62cCkHAgT0VsIX6WztMhp-gzGzoHsz',
	  appKey: 'n1lX9eWfotXltQ6Cab3ngGfk',
	  serverURLs: 'https://l0w62cck.lc-cn-n1-shared.com' || ' '
    }
  </script>
  <!-- site analysis -->
  

	<!-- site-analysis -->
	
	<script>
		var _hmt = _hmt || [];
		(function() {
			var hm = document.createElement("script");
			hm.src = "//hm.baidu.com/hm.js?b702b9b0aa72233c214dcbade17a5a27";
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(hm, s);
		})();
	</script>

	
	
	
	
 
    <meta name="referrer" content="no-referrer"/>
<meta name="generator" content="Hexo 6.3.0"></head>
	<body>
		<!-- Preloader -->


<!-- header -->
<header class="fixbackground">
		<div class="header-wrapper">
		<ul id="global-nav">
	
		<li class="menu-home">
			<a href="/" class="menu-item-home" target="_blank">主页</a>
		</li>
		
	
		<li class="menu-archive">
			<a href="/archives" class="menu-item-archive" target="_blank">归档</a>
		</li>
		
	
		<li class="menu-categories">
			<a href="/categories" class="menu-item-categories" target="_blank">分类</a>
		</li>
		
	
		<li class="menu-tags">
			<a href="/tags" class="menu-item-tags" target="_blank">标签</a>
		</li>
		
	
		<li class="menu-about">
			<a href="/about" class="menu-item-about" target="_blank">关于</a>
		</li>
		
	

	
		<li class="menu-search">
			<a href="javascript:;" class="popup-trigger">搜索</a>
		</li>
	
</ul>
	</div>
	<div class="mask">
	<div class="banner-frame border-image" style="border-image-source: url('https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/mask.png');"></div>
		<div class="container">
			<div class="row">
				<div class="col-md-12">
					<div class="align">
						<h1 class="h1 light">Songqian Li&#39;s Blog</h1>
						<div class="empty-space col-xs-b15"></div>
						<div class="sa light large">C U</div>
						<div class="empty-space col-xs-b30"></div>
					</div>
				</div>
			</div>
		</div>
		<!-- motto -->
		<div class="h-body">	
			
		</div>
		
		<!-- others: such as time... -->			
		<div class="h-footer">
			<a href="javascript:;" id="read-more" class="scroll-down">
				<span class="icon-anchor1 animation-scroll-down"></span>
			</a>
		</div>
	</div>
</header>

<div id="navigation-hide">
	<!-- Progress bar -->
	<div id="progress-bar"></div>

	<!-- Progress percent -->
	<div id="progress-percentage"><span>0.0%</span></div>

	<div class="toc-switch"><span class="switch-button">目录</span></div>

	<!-- Page title -->
	<p>
		
			「我发现了Transformer模型的秘密」
		
	</p>

	
	

	<!-- Nav trigger for navigation-H-->
	<a class="nav-trigger"><span></span></a>
</div>

<!-- Navigation in div(id="navigation-H") -->
<nav class="nav-container" id="cd-nav">
	<div class="nav-header">
		<!--<span class="logo"> 
			<img src="/img/logo.png">
		</span> -->
		<a href="javascript:;" class="nav-close"></a>
	</div>
	
	<div class="nav-body">
		<ul id="global-nav">
	
		<li class="menu-home">
			<a href="/" class="menu-item-home" target="_blank">主页</a>
		</li>
		
	
		<li class="menu-archive">
			<a href="/archives" class="menu-item-archive" target="_blank">归档</a>
		</li>
		
	
		<li class="menu-categories">
			<a href="/categories" class="menu-item-categories" target="_blank">分类</a>
		</li>
		
	
		<li class="menu-tags">
			<a href="/tags" class="menu-item-tags" target="_blank">标签</a>
		</li>
		
	
		<li class="menu-about">
			<a href="/about" class="menu-item-about" target="_blank">关于</a>
		</li>
		
	

	
		<li class="menu-search">
			<a href="javascript:;" class="popup-trigger">搜索</a>
		</li>
	
</ul>
	</div>
	
	<div class="nav-footer">
		<ul id="global-social">
	
		<li>
			<a href="//github.com/lisongqian" target="_blank">
				<span class="icon-github"></span>
			</a>
		</li>
	
		<li>
			<a href="/atom.xml" target="_blank">
				<span class="icon-rss"></span>
			</a>
		</li>
			
</ul>

	</div>
</nav>
			
		<!--main-->
		<main>
			<!--
	时间：2018-11-17
	描述：
		插件名称：katelog.min.js
		插件作者：KELEN
		插件来源: https://github.com/KELEN/katelog
-->
	 

<div class="layout-post">
	<div id="layout-post">
		<div class="article-title">
			
	<a href="/2021/02/22/yuque/aih1sz/" itemprop="url">
		我发现了Transformer模型的秘密
	</a>

		</div>

		<div class="article-meta">
			<span>
				<i class="icon-calendar1"></i>
				
				




	更新于

	<a href="/2021/02/22/yuque/aih1sz/" itemprop="url">
		<time datetime="2021-02-22T08:06:27.000Z" itemprop="dateUpdated">
	  		2022-12-25
	  </time>
	</a> 



			</span>
			<span>
				
	<i class="icon-price-tags"></i>
	
		<a href="/tags/MachineLearning/" class=" ">
			MachineLearning
		</a>
	
		<a href="/tags/Transformer/" class=" ">
			Transformer
		</a>
	
		
			</span>
			
			



		</div>

		<div class="article-content" id="article-content">
			<p>本文希望从 Base-Attention 到 Transformer 逐层递进的解释其中的计算细节,从而更好的理解 Transformer 模型。本文主要对模型可能存在的盲区进行解释，可能思路有些跳跃，请谅解。参考资料见文章末尾<code>Reference</code>.</p>
<h3 id="Base-Attention"><a href="#Base-Attention" class="headerlink" title="Base-Attention"></a>Base-Attention</h3><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412100228393.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191446-67eb1d4a-2bf5-43a1-ad9b-ca860f871f86.png#crop=0&crop=0&crop=1&crop=1&height=337&id=MyNvs&originHeight=337&originWidth=709&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=709"></a><br>如左图所示，为了实现<code>Attention</code>机制，我们需要一个 Z0Z0，与 h1h1 计算得到一个<code>scale</code>α10α01，这个 α10α01 可以简单看做 hh 与 zz 的相似度.<br>将 Z0Z0 与每一个 hihi 进行相乘然后 SoftmaxSoftmax 计算得到<code>distribution</code> αi0α0i，就变成了右图。这个<code>distribution</code>就是<code>Attention</code>机制的<code>Weight</code>。得到<code>Attention</code>之后将^αi0α^0i 乘上 hihi 后加到一起形成<code>Vector</code>C0C0，C0C0 就是预测第一个单词的特征向量。<br>注：本例中的<code>Value</code>是与<code>Key</code>相同的，但是实际上<code>Value</code>可以与<code>Key</code>不同，因为<code>Key</code>是用来计算<code>Attention</code>的<code>Weight</code>αα 的，而<code>Value</code>是用来与 αα 相乘得到<code>Vector</code>的，因此<code>Key</code>与<code>Value</code>不需要一定相同。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412140538223.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191409-c1a2c26f-0492-48c1-83ed-e5b13ea0fc08.png#crop=0&crop=0&crop=1&crop=1&height=491&id=NerWi&originHeight=491&originWidth=777&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=777"></a><br><code>Dot-Product Attention</code>是 Base 的一种计算方式，图中表示了 Attention 的计算公式以及相对应的 Q,K,VQ,K,V 的维度。</p>
<h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h3><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412153633191.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191348-39d55af7-ac0e-4e08-a7bf-f13f5133af42.png#crop=0&crop=0&crop=1&crop=1&height=813&id=KZHfG&originHeight=813&originWidth=1429&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1429"></a><br><code>Self-Attention</code>主要解决了训练时的并行问题，计算每个单词<code>Attention</code>时不用等前一个单词计算完成即可开始计算，以图中<code>a</code>为例。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412211908862.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191505-c0d8df7d-2e88-4774-85dd-43277d49ecfa.png#crop=0&crop=0&crop=1&crop=1&height=745&id=z81FI&originHeight=745&originWidth=1263&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1263"></a><br>如图以 e2e2 为例，把自身的<code>vector</code>作为<code>Query</code>，Dot-Product 的<code>Key</code>就是 e1e1。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200415141938375.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191415-c7c1a9c2-7f46-4faf-becc-3fb58b2680d3.png#crop=0&crop=0&crop=1&crop=1&height=480&id=iJ4wd&originHeight=480&originWidth=818&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=818"></a><br>而在 decoder 的时候需要把 e2e2 后面的词给 mask 掉，因为<code>inference</code>阶段是没有后面输入。</p>
<h3 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h3><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200413154942609.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191498-39e92559-6df0-49be-8cc0-a0b758712b0f.png#crop=0&crop=0&crop=1&crop=1&height=819&id=zujCA&originHeight=819&originWidth=1523&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1523"></a><br>对<code>Multi-Head Attention</code>的相关解释如图所示。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200415143424126.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191416-b40d8540-979a-488a-9cd5-fb29b0b93734.png#crop=0&crop=0&crop=1&crop=1&height=470&id=SnRl7&originHeight=470&originWidth=946&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=946"></a><br><code>Scaled Dot-Product Attention</code>的<code>h</code>指的是<code>Multi-Head Attention</code>的数量。</p>
<h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412202544188.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191283-020828b2-a4c5-4bb8-8b82-c67e97aa4700.png#crop=0&crop=0&crop=1&crop=1&height=787&id=Lvblk&originHeight=787&originWidth=1203&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1203"></a><br>Transformer 就是用 Self-Attention 替换了序列模型的 RNN 单元。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200413171304672.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191456-955a4543-3b44-4454-9a74-62a0caa31e5f.png#crop=0&crop=0&crop=1&crop=1&height=808&id=ui53z&originHeight=808&originWidth=1536&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1536"></a><br>本图主要解释了加入<code>Scaled</code>过程的原因，如上图中间的图像所示，蓝色是 QKTQKT，橙色是 softmax(QKT)softmax(QKT)，明显可以看出函数变的很尖，这样导致梯度变得很小，只有高数值的信息才会使模型更新，因此为了解决这个问题，在计算 softmax 之前除以 √dkdk。<br>这里可以理解为两个独立的矩阵，均值为 0，方差为 1。经过矩阵相乘之后，均值还是 0，方差会变成 dkdk，这样就会导致 Softmax 之后梯度变得很小。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200413180003131.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191232-6a6d2be0-4e0b-4f71-b201-3255af6d5801.png#crop=0&crop=0&crop=1&crop=1&height=812&id=RdrBk&originHeight=812&originWidth=1468&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1468"></a><br>residual connection 是指经过一个 F(x)F(x)后，输出结果是 F(x)+xF(x)+x，这样做的目的是为了解决模型在多次进行 F(x)F(x)计算之后没有更多的<code>signore</code>的时候,模型可以弹性的选择哪部分要经过 F(x)F(x)，哪部分可以跳过 F(x)F(x)，而且模型也不需要更多的参数来进行训练。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200414151913660.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981192468-01860395-b3e6-4d10-a442-6b36575eeb33.png#crop=0&crop=0&crop=1&crop=1&height=804&id=na2lw&originHeight=804&originWidth=1528&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1528"></a><br>在<code>Decoder</code>中，因为序列的预测过程是从左往右，所以右面单词的<code>Attention</code>是未知的，这就是绿色框中<code>Masked</code>与红色框之间有区别的原因。<br>在蓝色框中，<code>Decoder</code>提供 Attention 的<code>Query</code>，<code>Encoder</code>提供 Attenion 的<code>Key</code>和<code>Query</code>。</p>
<h3 id="Training-Trick"><a href="#Training-Trick" class="headerlink" title="Training Trick"></a>Training Trick</h3><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200414164511250.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981192403-78e67c1e-c92b-425f-b2ad-c2fec0ea0713.png#crop=0&crop=0&crop=1&crop=1&height=511&id=rvLM9&originHeight=511&originWidth=1248&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1248"></a></p>
<h4 id="Byte-pair-encodings"><a href="#Byte-pair-encodings" class="headerlink" title="Byte-pair encodings"></a>Byte-pair encodings</h4><p>BPE 算法的基本思路是把经常出现的<code>byte pair</code>用一个新的<code>byte</code>来代替，例如假设<code>(&#39;A&#39;, ’B‘）</code>经常顺序出现，则用一个新的标志<code>&#39;AB&#39;</code>来代替它们。<br>例如，假设我们的文本库中出现的单词及其出现次数为<code>&#123;&#39;l o w&#39;: 5, &#39;l o w e r&#39;: 2, &#39;n e w e s t&#39;: 6, &#39;w i d e s t&#39;: 3&#125;</code>，我们的初始词汇库为<code>&#123; &#39;l&#39;, &#39;o&#39;, &#39;w&#39;, &#39;e&#39;, &#39;r&#39;, &#39;n&#39;, &#39;w&#39;, &#39;s&#39;, &#39;t&#39;, &#39;i&#39;, &#39;d&#39;&#125;</code>，出现频率最高的 ngram pair 是<code>(&#39;e&#39;,&#39;s&#39;)</code> 9 次，所以我们将’es’作为新的词汇加入到词汇库中，由于’es’作为一个整体出现在词汇库中，这时文本库可表示为 <code>&#123;&#39;l o w&#39;: 5, &#39;l o w e r&#39;: 2, &#39;n e w es t&#39;: 6, &#39;w i d es t&#39;: 3&#125;</code>，这时出现频率最高的 ngram pair 是<code>(&#39;es&#39;,&#39;t&#39;)</code>9 次，将’est’加入到词汇库中，文本库更新为<code>&#123;&#39;l o w&#39;: 5, &#39;l o w e r&#39;: 2, &#39;n e w est&#39;: 6, &#39;w i d est&#39;: 3&#125;</code>，新的出现频率最高的 ngram pair 是(‘l’,’o’)7 次，将’lo’加入到词汇库中，文本库更新为<code>&#123;&#39;lo w&#39;: 5, &#39;lo w e r&#39;: 2, &#39;n e w est&#39;: 6, &#39;w i d est&#39;: 3&#125;</code>。以此类推，直到词汇库大小达到我们所设定的目标。这个例子中词汇量较小，对于词汇量很大的实际情况，我们就可以通过 BPE 逐步建造一个较小的基于 subword unit 的词汇库来表示所有的词汇。</p>
<h4 id="Checkpoint-averaging"><a href="#Checkpoint-averaging" class="headerlink" title="Checkpoint averaging"></a>Checkpoint averaging</h4><p>对训练过程中 checkpoint 保存的模型进行参数平均</p>
<h4 id="Boom-Search："><a href="#Boom-Search：" class="headerlink" title="Boom Search："></a>Boom Search：</h4><ol>
<li><code>step 1</code>：在预测第一个单词的时候选择前<code>Beam width</code>个概率最大的单词作为第一个单词；</li>
<li><code>step 2</code>：假设词汇表长<code>10000</code>,<code>B=3</code>按照 P(y&lt;1&gt;,y&lt;2&gt;|x)&#x3D;P(y&lt;1&gt;|x)P(y&lt;2&gt;|x,y&lt;1&gt;)P(y&lt;1&gt;,y&lt;2&gt;|x)&#x3D;P(y&lt;1&gt;|x)P(y&lt;2&gt;|x,y&lt;1&gt;)最大，就会在开头为(y&lt;1&gt;,y&lt;2&gt;)(y&lt;1&gt;,y&lt;2&gt;)的<code>30000</code>种选择中选取概率最大的<code>3</code>种，并将(y&lt;1&gt;,y&lt;2&gt;)(y&lt;1&gt;,y&lt;2&gt;)作为新的开头；</li>
<li><code>step 3</code>：将<code>step 2</code>中选取的新的开头作为条件,重复计算<code>step 2</code>，如果遇到终止符则停止。</li>
</ol>
<p>改进集束搜索（改进其打分规则）：<br>由于$\displaystyle argmax \prod_{t&#x3D;1}^{T_y}P(y^{}|x,y^{1},\dots,y^{t-1})$，是多个小于 1 的概率相乘，最终得到的数值会很小很小，出现数值下溢，因此对上述公式取对数：<br>argmaxTy∑t&#x3D;1log,P(y|x,y1,…,yt−1)argmax∑t&#x3D;1Tylog,P(y|x,y1,…,yt−1)<br>但是 log 函数在(0,1)是负数，序列越长数值越低，所以模型会更倾向于短文本输出而不是简洁的文本。于是第二次改进：<br>1TαyTy∑t&#x3D;1log,P(y|x,y1,…,yt−1)1Tyα∑t&#x3D;1Tylog,P(y|x,y1,…,yt−1)<br>对和函数进行归一化，但是不是单纯的除以单词数量，而是除以 TyTy 的 αα 次幂，这里的 αα 是一个超参数。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV19g4y1b7vx?p=1">台大《应用深度学习》国语课程(2020) by 陈蕴侬</a></li>
<li><a target="_blank" rel="noopener" href="https://mooc.study.163.com/course/2001280005#/info">序列模型 by Andrew Ng</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/69414965">CS224N 笔记(十二):Subword 模型</a></li>
</ol>
	
		</div>
		
		<div id="current-post-cover" data-scr="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg"></div>

		<!-- relate post, comment...-->
		<div class="investment-container">
			<div class="investment-header">
				<div class="investment-title-1">
					<div class="on">相关文章</div>
					<div>评论</div>
					<div>分享</div>
				</div>
				<div class="investment-title-2">	            
					
	<span>
		<a id="totop-post-page">返回顶部</a>
		
			<a href="/2021/02/22/yuque/ecdpur/" title="你看不懂的BERT解读" rel="prev">
				&laquo;上一篇
			</a>
		
		
			<a href="/2021/01/28/yuque/xnw3ik/" title="Chrome自动将http切换为https" rel="next">
				下一篇&raquo;
			</a>
			
	</span>


      		
				</div>	
			</div>
			
			<div class="investment-content">
				<div class="investment-content-list">
					

<div class="relate-post">
	
		<ul>
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2021/02/22/yuque/qsv094/" title="使用PyTorch可视化必须知道的TensorBoard参数">
								使用PyTorch可视化必须知道的TensorBoard参数			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								二月 22日, 2021				
							</p>
							<p class="relate-post-content">
								亲测可用的PyTorch和TensorflowBoard版本，不会出现绘制模型结构图片时空白的情况。
1234torch==1.2.0tensorboard==2.1.1tensorflow==2.1.0tensorboardX==2...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2021/02/22/yuque/qsv094/" title="使用PyTorch可视化必须知道的TensorBoard参数">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="使用PyTorch可视化必须知道的TensorBoard参数"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2021/02/22/yuque/ecdpur/" title="你看不懂的BERT解读">
								你看不懂的BERT解读			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								二月 22日, 2021				
							</p>
							<p class="relate-post-content">
								本文主要是针对近年来序列模型的发展，例如 BERT、Transformer-XL、XLNet、RoBERTa 以及 XLM 等模型的思路整理。
BERT: Bidirectional Encoder Representations f...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2021/02/22/yuque/ecdpur/" title="你看不懂的BERT解读">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="你看不懂的BERT解读"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2020/04/07/yuque/xcb5hp/" title="正则化">
								正则化			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								四月 7日, 2020				
							</p>
							<p class="relate-post-content">
								
模型越复杂越容易出现过拟合状态，所以需要一种机制来保证我们模型的“简单”，这样我们的模型才能有较好的泛化能力，正则化是这类机制之一。

欧几里得范数：
L2 范数：
L1 范数：

推导过程
泰勒公式  

为什么可以减少过拟合
直...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2020/04/07/yuque/xcb5hp/" title="正则化">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="正则化"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2020/04/07/yuque/ehef5p/" title="机器学习常用算法原理">
								机器学习常用算法原理			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								四月 7日, 2020				
							</p>
							<p class="relate-post-content">
								Logistic Regression逻辑回归的假设函数：

其中是输入,是要求解的参数。
函数图像：

一个机器学习模型实际上是把决策函数限定在某组条件下，这组限定条件决定了模型的假设空间，逻辑回归的假设空间：

它的意思是在给定的...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2020/04/07/yuque/ehef5p/" title="机器学习常用算法原理">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="机器学习常用算法原理"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/12/18/yuque/yh5mcml2bb6o3kpg/" title="《操作系统真象还原》：第六章 完善内核">
								《操作系统真象还原》：第六章 完善内核			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								十二月 18日, 2022				
							</p>
							<p class="relate-post-content">
								6.1 函数调用约定简介咱们实验使用cdecl。这里提一下stdcall，cdecl与stdcall的区别在于由谁来回收栈空间。stdcall是被调用者清理参数所占的栈空间。举例来说：
12int subtract(int a, in...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/12/18/yuque/yh5mcml2bb6o3kpg/" title="《操作系统真象还原》：第六章 完善内核">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="《操作系统真象还原》：第六章 完善内核"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/12/11/yuque/mguvy5fxrt54cg9m/" title="《操作系统真象还原》：第五章 保护模式进阶——加载内核">
								《操作系统真象还原》：第五章 保护模式进阶——加载内核			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								十二月 11日, 2022				
							</p>
							<p class="relate-post-content">
								5.3 加载内核5.3.1 用 C 语言写内核第一个 C 语言代码：
1234int main(void) &#123;	while(1);	return 0;&#125;

这个内核文件什么都没做，通过while(1)这个死循环一直...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/12/11/yuque/mguvy5fxrt54cg9m/" title="《操作系统真象还原》：第五章 保护模式进阶——加载内核">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="《操作系统真象还原》：第五章 保护模式进阶——加载内核"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/11/19/yuque/eg33ul1eh4zf6lzi/" title="《操作系统真象还原》：第五章 保护模式进阶——内存分页机制">
								《操作系统真象还原》：第五章 保护模式进阶——内存分页机制			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								十一月 19日, 2022				
							</p>
							<p class="relate-post-content">
								
从这一刻起，我们才算开始了真正的操作系统学习之旅

5.1 获取物理内存容量5.1.1 Linux 获取内存的方法在 Linux 2.6 内核总是用detect_memory函数来获取内存容量的。其函数子啊本质上是通过调用 BIOS...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/11/19/yuque/eg33ul1eh4zf6lzi/" title="《操作系统真象还原》：第五章 保护模式进阶——内存分页机制">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="《操作系统真象还原》：第五章 保护模式进阶——内存分页机制"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/11/08/yuque/qmb3g6pmmzfkbxg5/" title="《操作系统真象还原》：第四章 保护模式入门">
								《操作系统真象还原》：第四章 保护模式入门			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								十一月 8日, 2022				
							</p>
							<p class="relate-post-content">
								4.1 保护模式概述在本章大家会见到全局描述符表、中断描述符表、各种门结构，这是 CPU 提供给应用的，咱们用好就行。保护模式强调的是“保护”，它是在 Intel 80286 CPU 中首次出现，这是继 8086 之后，Intel 紧...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/11/08/yuque/qmb3g6pmmzfkbxg5/" title="《操作系统真象还原》：第四章 保护模式入门">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="《操作系统真象还原》：第四章 保护模式入门"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/09/25/yuque/fvxk1z/" title="《操作系统真象还原》：第三章 完善MBR——I/O接口">
								《操作系统真象还原》：第三章 完善MBR——I/O接口			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								九月 25日, 2022				
							</p>
							<p class="relate-post-content">
								3.3 让我们对显示器说点什么吧3.3.1 CPU 如何与外设通信——IO 接口IO 接口功能：

设置数据缓冲，解决 CPU 与外设的速度不匹配
设置信号电平转换电路
设置数据格式转换
设置时序控制电路来同步 CPU 和外部设备
提...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/09/25/yuque/fvxk1z/" title="《操作系统真象还原》：第三章 完善MBR——I/O接口">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="《操作系统真象还原》：第三章 完善MBR——I/O接口"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/09/11/yuque/xa16pm/" title="《操作系统真象还原》：第三章 完善MBR——CPU的实模式">
								《操作系统真象还原》：第三章 完善MBR——CPU的实模式			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								九月 11日, 2022				
							</p>
							<p class="relate-post-content">
								针对汇编几个知识点：

第 1 行和第 4 行的 mov 操作，机器码第 1 个宇节都是B8，而另外第 2、3 行同样是 mov 指令，机器码却有天壤之别，似乎找不到共性。原因是机器码是由很多部分组成的，比如指令前缀、主操作码字节以及...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/09/11/yuque/xa16pm/" title="《操作系统真象还原》：第三章 完善MBR——CPU的实模式">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="《操作系统真象还原》：第三章 完善MBR——CPU的实模式"/>
							</a>
						</div>
					</li>												
			
		</ul>
	
</div>	
				</div>
				<div class="investment-content-list">
					<div class="layout-comment">

	

		

			<!-- gitalk comment -->
			<!-- show gitalk comment -->
<div id="gitalk-container"></div>

<!-- gitalk`s css & js -->
<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<link rel="stylesheet" href="/css/comment.css">
<script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<script type="text/javascript">

	(function gitalkComment(){
		//Thanks O-R
		//https://github.com/gitalk/gitalk/issues/102#issuecomment-382970552
		//去除尾部匹配正则数组的字符串  
		//Remove redundant characters
		String.prototype.trimEnd = function(regStr) {
			let result = this;
			if(regStr == undefined || regStr == null || regStr == "") {
				return result;
			}
			let array = regStr.split(',');

			if(array.length > 0) {

				let c = array.shift(), 
					str = this,
					i = str.length,
					rg = new RegExp(c),
					matchArr = str.match(rg);

				if(matchArr != undefined && matchArr != null && matchArr.length > 0) {
					let matchStr = matchArr[0].replace(/\\/g, "\\\\").replace(/\*/g, "\\*")
						.replace(/\+/g, "\\+").replace(/\|/g, "\\|")
						.replace(/\{/g, "\\{").replace(/\}/g, "\\}")
						.replace(/\(/g, "\\(").replace(/\)/g, "\\)")
						.replace(/\^/g, "\\^").replace(/\$/g, "\\$")
						.replace(/\[/g, "\\[").replace(/\]/g, "\\]")
						.replace(/\?/g, "\\?").replace(/\,/g, "\\,")
						.replace(/\./g, "\\.").replace(/\&/g, "\\&");
					matchStr = matchStr + '$';
					result = str.replace(new RegExp(matchStr), "");
				}

				if(array.length > 0) {
					return result.trimEnd(array.join())
				} else {
					return result;
				}
			}
		};

		//Create gitalk
		let gitalk = new Gitalk({
			clientID: '693063c1941dbc1701d3',
			clientSecret: 'f88ddf502ef33ce91ce9d8c140dbc7e3a0653b7e',
			//id: window.location.pathname,
			//id: decodeURI(window.location.pathname),
			//id: (window.location.pathname).split("/").pop().substring(0, 49),
			id: decodeURI( md5( location.href.trimEnd('#.*$,\\?.*$,index.html$') ) ),
			repo: 'lisongqian.github.io',
			owner: 'lisongqian',
			admin: 'lisongqian',
			distractionFreeMode: 'false',
		})
		gitalk.render('gitalk-container');		
	})();
</script>

		
		
	

</div>
				</div>
				<div class="investment-content-list">
					<div class="layout-share">
	
	

		
			
			<!-- socialShare share -->
			<div class="social-share"></div>

<!--  css & js -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>
			
		
		
	
</div>


				</div>
			</div>	
		</div>
	</div>
</div>

<!-- show math formula -->



	





<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">


<script src="/plugin/fancybox/jquery.fancybox.js"></script>


<script type="text/javascript">
	(function gallerySet(){
		let titleID = $('.article-title a'),
			imageID = $('.article-content img'),
			videoID = $('.article-content video');
		
		let postTitle = titleID.text() ? titleID.text() : "No post title!";
		
		imageID.each(function() {
			let imgPath = $(this).attr('src'),
				imgTitle = $(this).attr('alt') ? $(this).attr('alt') : "No image description!";
		
			//给每个匹配的<img>元素打包, 即添加父元素<a>
			$(this).wrap('<a data-fancybox="gallery" data-caption="《 ' + postTitle + ' 》' + imgTitle + '"href="' + imgPath + '"> </a>');
		});
		
		videoID.each(function() {
			let videoPath = $(this).attr('src');
		
			//给每个匹配的<img>元素打包, 即添加父元素<a>
			$(this).wrap('<a data-fancybox href=" ' + videoPath + ' "> </a>');
		});
		
		//TODO：支持html5 video

		if($('#layout-post').length) {
			$('[data-fancybox="gallery"]').fancybox({
				loop: true,
				buttons: [
					"zoom",
					"share",
					"slideShow",
					"fullScreen",
					//"download",
					"thumbs",
					"close"
				],
				protect: true
			});
		}
	})();
</script>
		</main>

		<!--footer-->
		<footer>
	<div id="navigation-show">
		<ul id="global-nav">
	
		<li class="menu-home">
			<a href="/" class="menu-item-home" target="_blank">主页</a>
		</li>
		
	
		<li class="menu-archive">
			<a href="/archives" class="menu-item-archive" target="_blank">归档</a>
		</li>
		
	
		<li class="menu-categories">
			<a href="/categories" class="menu-item-categories" target="_blank">分类</a>
		</li>
		
	
		<li class="menu-tags">
			<a href="/tags" class="menu-item-tags" target="_blank">标签</a>
		</li>
		
	
		<li class="menu-about">
			<a href="/about" class="menu-item-about" target="_blank">关于</a>
		</li>
		
	

	
		<li class="menu-search">
			<a href="javascript:;" class="popup-trigger">搜索</a>
		</li>
	
</ul>
	</div>

	<div class="copyright">
		<p>
		<a href="http://www.beian.miit.gov.cn/" target="_blank" rel="noopener">鲁ICP备16042410号</a>
			 
				&copy;2017 - 2022, content by SongqianLi. All Rights Reserved.
			
			
				<a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> Theme <a href="https://github.com/Sariay/hexo-theme-Annie" title="Annie" target="_blank" rel="noopener">Annie</a> by Sariay.
			
		</p>
		<p>
			

	<!-- busuanzi -->
	<!-- busuanzi -->



			<a href="javascript:zh_tran('s');" class="zh_click" id="zh_click_s">简体</a> 
			<a href="javascript:zh_tran('t');" class="zh_click" id="zh_click_t">繁體</a>				
		</p>
	</div>		
</footer>
		

<!-- love effect -->


<!-- back to top -->

	<div id="totop">
	<span class="icon-circle-up"></span>
</div>




<!-- leancloud -->


	<!-- leancloud -->
	<!--
	时间：2018-11-27
	描述：
		文章访问量：visitors
		文章喜欢量：likes	
		文章排行榜：topNPost
		其他得说明：
			01-Cookie相关的函数 
				https://blog.csdn.net/somehow1002/article/details/78511541（Author：somehow1002）
			02-visitors相关的函数 
				https://blog.csdn.net/u013553529/article/details/63357382（Author：爱博客大伯）
				https://notes.doublemine.me/2015-10-21-为NexT主题添加文章阅读量统计功能.html（Author：夏末）
			03-topNPost相关的函数
				https://hoxis.github.io/hexo-next-read-rank.html（Author：hoxis）
			04-likes相关的函数，
				参考了01 & 02进行简单的设计与实现
-->


  
<script src="/plugin/leancloud/av-min.js"></script>
<script src="/js/leancloud-count.js"></script>


	

  

	<!--
	时间：2018-10-3
	描述：
		插件名称：hexo-generator-search-zip
		插件来源: https://github.com/SuperKieran/hexo-generator-search-zip
		代码参考：https://github.com/SuperKieran/TKL/blob/master/layout/_partial/search.ejs(Include: js & css)	
-->
<div class="popup search-popup local-search-popup scrollbar" >
	<div class="local-search-container">
		<span class="popup-btn-close">
      		ESC
   		</span>
		<div class="local-search-header">
			<div class="input-prompt">				
			</div>
			<input autocomplete="off" placeholder="Search..." type="text" id="local-search-input">
		</div>
		<div class="local-search-body">
			<div id="local-search-output"></div>
		</div>
		<div class="local-search-footer">
			<div class="topN-post">				
				

   
	<div id="topN">
		<div class="topN-title" data-title= "热门文章"></div> 
	</div>
	
    <script>
        var limitCount = 10;
        if( $('#topN').length ){
            setTimeout(function() {
                topNPost(limitCount);
			}, 3000);
        }
    </script>
   
								
			</div>
		</div>
	</div>
</div>


<script src="/plugin/search/ziploader.js"></script>
<script src="/js/search.js"></script>


<script type="text/javascript">
	var search_path = 'search.json',
		zip_Path = '/search.zip',
		version_Path = '/searchVersion.txt',
		input_Trigger = 'auto',
		top_N = '2';

	themeLocalSearch({
		search_path, 
		zip_Path, 
		version_Path, 
		input_Trigger, 
		top_N
	});
</script>



<script src="/plugin/chinese/chinese.js"></script>
<script src="/plugin/imagelazyloader/yall.min.js"></script>
<script src="/plugin/imageloaded/imagesloaded.pkgd.min.js"></script>
<script src="/plugin/resizediv/resizediv.js"></script>
<script src="/js/main.js"></script>

	</body>	
</html>