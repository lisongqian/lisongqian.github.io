<!--
	作者：Sariay
	时间：2018-08-26
	描述：There may be a bug, but don't worry, Qiling(器灵) says that it can work normally! aha!
-->
<!DOCTYPE html>
<html class="html-loading">
		

<head>
	<meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
  <title>
    
      我发现了Transformer模型的秘密 | Songqian Li&#39;s Blog
    
  </title>
  <meta name="author" content="Songqian Li">
  <meta name="keywords" content="" />
  <meta name="description" content="去历史上留点故事" />
	<!-- favicon -->
  <link rel="shortcut icon" href="/img/favicon.ico">
<!--  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Playfair+Display:400,700,900">-->
  <link rel="stylesheet" href="https://fonts.font.im/css?family=Playfair+Display:400,700,900">
  <!-- css -->
  
<link rel="stylesheet" href="/css/Annie.css">

  
  <!-- jquery -->
	
<script src="/plugin/jquery/jquery.min.js"></script>


<script>
    const CONFIG_BGIMAGE = {
      mode: 'normal',
      normalSrc: '/img/header-bg.jpg',
      randomYouMax: 110,
      randomYouSrc: 'https://sariay.github.io/Random-img/',
	  randomOtherSrc: 'https://api.berryapi.net/?service=App.Bing.Images&day=-0',
	  preloaderEnable: false
    }
	
    const CONFIG_LEACLOUD_COUNT = {
      enable: false,
	  appId: 'L0W62cCkHAgT0VsIX6WztMhp-gzGzoHsz',
	  appKey: 'n1lX9eWfotXltQ6Cab3ngGfk',
	  serverURLs: 'https://l0w62cck.lc-cn-n1-shared.com' || ' '
    }
  </script>
  <!-- site analysis -->
  

	<!-- site-analysis -->
	
	<script>
		var _hmt = _hmt || [];
		(function() {
			var hm = document.createElement("script");
			hm.src = "//hm.baidu.com/hm.js?b702b9b0aa72233c214dcbade17a5a27";
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(hm, s);
		})();
	</script>

	
	
	
	
 
    <meta name="referrer" content="no-referrer"/>
<meta name="generator" content="Hexo 6.3.0"></head>
	<body>
		<!-- Preloader -->


<!-- header -->
<header class="fixbackground">
		<div class="header-wrapper">
		<ul id="global-nav">
	
		<li class="menu-home">
			<a href="/" class="menu-item-home" target="_blank">主页</a>
		</li>
		
	
		<li class="menu-archive">
			<a href="/archives" class="menu-item-archive" target="_blank">归档</a>
		</li>
		
	
		<li class="menu-categories">
			<a href="/categories" class="menu-item-categories" target="_blank">分类</a>
		</li>
		
	
		<li class="menu-tags">
			<a href="/tags" class="menu-item-tags" target="_blank">标签</a>
		</li>
		
	
		<li class="menu-about">
			<a href="/about" class="menu-item-about" target="_blank">关于</a>
		</li>
		
	

	
		<li class="menu-search">
			<a href="javascript:;" class="popup-trigger">搜索</a>
		</li>
	
</ul>
	</div>
	<div class="mask">
	<div class="banner-frame border-image" style="border-image-source: url('/img/mask.png');"></div>
		<div class="container">
			<div class="row">
				<div class="col-md-12">
					<div class="align">
						<h1 class="h1 light">Songqian Li&#39;s Blog</h1>
						<div class="empty-space col-xs-b15"></div>
						<div class="sa light large">去历史上留点故事</div>
						<div class="empty-space col-xs-b30"></div>
					</div>
				</div>
			</div>
		</div>
		<!-- motto -->
		<div class="h-body">	
			
		</div>
		
		<!-- others: such as time... -->			
		<div class="h-footer">
			<a href="javascript:;" id="read-more" class="scroll-down">
				<span class="icon-anchor1 animation-scroll-down"></span>
			</a>
		</div>
	</div>
</header>

<div id="navigation-hide">
	<!-- Progress bar -->
	<div id="progress-bar"></div>

	<!-- Progress percent -->
	<div id="progress-percentage"><span>0.0%</span></div>

	<div class="toc-switch"><span class="switch-button">目录</span></div>

	<!-- Page title -->
	<p>
		
			「我发现了Transformer模型的秘密」
		
	</p>

	
	

	<!-- Nav trigger for navigation-H-->
	<a class="nav-trigger"><span></span></a>
</div>

<!-- Navigation in div(id="navigation-H") -->
<nav class="nav-container" id="cd-nav">
	<div class="nav-header">
		<!--<span class="logo"> 
			<img src="/img/logo.png">
		</span> -->
		<a href="javascript:;" class="nav-close"></a>
	</div>
	
	<div class="nav-body">
		<ul id="global-nav">
	
		<li class="menu-home">
			<a href="/" class="menu-item-home" target="_blank">主页</a>
		</li>
		
	
		<li class="menu-archive">
			<a href="/archives" class="menu-item-archive" target="_blank">归档</a>
		</li>
		
	
		<li class="menu-categories">
			<a href="/categories" class="menu-item-categories" target="_blank">分类</a>
		</li>
		
	
		<li class="menu-tags">
			<a href="/tags" class="menu-item-tags" target="_blank">标签</a>
		</li>
		
	
		<li class="menu-about">
			<a href="/about" class="menu-item-about" target="_blank">关于</a>
		</li>
		
	

	
		<li class="menu-search">
			<a href="javascript:;" class="popup-trigger">搜索</a>
		</li>
	
</ul>
	</div>
	
	<div class="nav-footer">
		<ul id="global-social">
	
		<li>
			<a href="//github.com/lisongqian" target="_blank">
				<span class="icon-github"></span>
			</a>
		</li>
	
		<li>
			<a href="/atom.xml" target="_blank">
				<span class="icon-rss"></span>
			</a>
		</li>
			
</ul>

	</div>
</nav>
			
		<!--main-->
		<main>
			<!--
	时间：2018-11-17
	描述：
		插件名称：katelog.min.js
		插件作者：KELEN
		插件来源: https://github.com/KELEN/katelog
-->

	
		<div class="layout-toc">
			<div id="layout-toc">
				<div class="k-catelog-list" id="catelog-list" data-title="文章目录"></div>
			</div>
		</div>

		
<script src="/plugin/toc/katelog.min.js"></script>


		
	 

<div class="layout-post">
	<div id="layout-post">
		<div class="article-title">
			
	<a href="/2021/02/22/yuque/aih1sz/" itemprop="url">
		我发现了Transformer模型的秘密
	</a>

		</div>

		<div class="article-meta">
			<span>
				<i class="icon-calendar1"></i>
				
				




	更新于

	<a href="/2021/02/22/yuque/aih1sz/" itemprop="url">
		<time datetime="2021-02-22T08:06:27.000Z" itemprop="dateUpdated">
	  		2024-03-02
	  </time>
	</a> 



			</span>
			<span>
				
	<i class="icon-price-tags"></i>
	
		<a href="/tags/MachineLearning/" class=" ">
			MachineLearning
		</a>
	
		<a href="/tags/Transformer/" class=" ">
			Transformer
		</a>
	
		
			</span>
			
			



		</div>

		<div class="article-content" id="article-content">
			<p>本文希望从 Base-Attention 到 Transformer 逐层递进的解释其中的计算细节,从而更好的理解 Transformer 模型。本文主要对模型可能存在的盲区进行解释，可能思路有些跳跃，请谅解。参考资料见文章末尾<code>Reference</code>.</p>
<h3 id="base-attention"><a class="markdownIt-Anchor" href="#base-attention"></a> Base-Attention</h3>
<p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412100228393.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191446-67eb1d4a-2bf5-43a1-ad9b-ca860f871f86.png#height=337&amp;id=MyNvs&amp;originHeight=337&amp;originWidth=709&amp;originalType=binary%E2%88%B6=1&amp;rotation=0&amp;showTitle=false&amp;size=0&amp;status=done&amp;style=none&amp;title=&amp;width=709" alt="" /></a><br />
如左图所示，为了实现<code>Attention</code>机制，我们需要一个 Z0Z0，与 h1h1 计算得到一个<code>scale</code>α10α01，这个 α10α01 可以简单看做 hh 与 zz 的相似度.<br />
将 Z0Z0 与每一个 hihi 进行相乘然后 SoftmaxSoftmax 计算得到<code>distribution</code> αi0α0i，就变成了右图。这个<code>distribution</code>就是<code>Attention</code>机制的<code>Weight</code>。得到<code>Attention</code>之后将<sup>αi0α</sup>0i 乘上 hihi 后加到一起形成<code>Vector</code>C0C0，C0C0 就是预测第一个单词的特征向量。<br />
注：本例中的<code>Value</code>是与<code>Key</code>相同的，但是实际上<code>Value</code>可以与<code>Key</code>不同，因为<code>Key</code>是用来计算<code>Attention</code>的<code>Weight</code>αα 的，而<code>Value</code>是用来与 αα 相乘得到<code>Vector</code>的，因此<code>Key</code>与<code>Value</code>不需要一定相同。<br />
<a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412140538223.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191409-c1a2c26f-0492-48c1-83ed-e5b13ea0fc08.png#height=491&amp;id=NerWi&amp;originHeight=491&amp;originWidth=777&amp;originalType=binary%E2%88%B6=1&amp;rotation=0&amp;showTitle=false&amp;size=0&amp;status=done&amp;style=none&amp;title=&amp;width=777" alt="" /></a><br />
<code>Dot-Product Attention</code>是 Base 的一种计算方式，图中表示了 Attention 的计算公式以及相对应的 Q,K,VQ,K,V 的维度。</p>
<h3 id="self-attention"><a class="markdownIt-Anchor" href="#self-attention"></a> Self-Attention</h3>
<p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412153633191.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191348-39d55af7-ac0e-4e08-a7bf-f13f5133af42.png#height=813&amp;id=KZHfG&amp;originHeight=813&amp;originWidth=1429&amp;originalType=binary%E2%88%B6=1&amp;rotation=0&amp;showTitle=false&amp;size=0&amp;status=done&amp;style=none&amp;title=&amp;width=1429" alt="" /></a><br />
<code>Self-Attention</code>主要解决了训练时的并行问题，计算每个单词<code>Attention</code>时不用等前一个单词计算完成即可开始计算，以图中<code>a</code>为例。<br />
<a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412211908862.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191505-c0d8df7d-2e88-4774-85dd-43277d49ecfa.png#height=745&amp;id=z81FI&amp;originHeight=745&amp;originWidth=1263&amp;originalType=binary%E2%88%B6=1&amp;rotation=0&amp;showTitle=false&amp;size=0&amp;status=done&amp;style=none&amp;title=&amp;width=1263" alt="" /></a><br />
如图以 e2e2 为例，把自身的<code>vector</code>作为<code>Query</code>，Dot-Product 的<code>Key</code>就是 e1e1。<br />
<a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200415141938375.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191415-c7c1a9c2-7f46-4faf-becc-3fb58b2680d3.png#height=480&amp;id=iJ4wd&amp;originHeight=480&amp;originWidth=818&amp;originalType=binary%E2%88%B6=1&amp;rotation=0&amp;showTitle=false&amp;size=0&amp;status=done&amp;style=none&amp;title=&amp;width=818" alt="" /></a><br />
而在 decoder 的时候需要把 e2e2 后面的词给 mask 掉，因为<code>inference</code>阶段是没有后面输入。</p>
<h3 id="multi-head-attention"><a class="markdownIt-Anchor" href="#multi-head-attention"></a> Multi-Head Attention</h3>
<p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200413154942609.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191498-39e92559-6df0-49be-8cc0-a0b758712b0f.png#height=819&amp;id=zujCA&amp;originHeight=819&amp;originWidth=1523&amp;originalType=binary%E2%88%B6=1&amp;rotation=0&amp;showTitle=false&amp;size=0&amp;status=done&amp;style=none&amp;title=&amp;width=1523" alt="" /></a><br />
对<code>Multi-Head Attention</code>的相关解释如图所示。<br />
<a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200415143424126.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191416-b40d8540-979a-488a-9cd5-fb29b0b93734.png#height=470&amp;id=SnRl7&amp;originHeight=470&amp;originWidth=946&amp;originalType=binary%E2%88%B6=1&amp;rotation=0&amp;showTitle=false&amp;size=0&amp;status=done&amp;style=none&amp;title=&amp;width=946" alt="" /></a><br />
<code>Scaled Dot-Product Attention</code>的<code>h</code>指的是<code>Multi-Head Attention</code>的数量。</p>
<h3 id="transformer"><a class="markdownIt-Anchor" href="#transformer"></a> Transformer</h3>
<p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200412202544188.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191283-020828b2-a4c5-4bb8-8b82-c67e97aa4700.png#height=787&amp;id=Lvblk&amp;originHeight=787&amp;originWidth=1203&amp;originalType=binary%E2%88%B6=1&amp;rotation=0&amp;showTitle=false&amp;size=0&amp;status=done&amp;style=none&amp;title=&amp;width=1203" alt="" /></a><br />
Transformer 就是用 Self-Attention 替换了序列模型的 RNN 单元。<br />
<a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200413171304672.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191456-955a4543-3b44-4454-9a74-62a0caa31e5f.png#height=808&amp;id=ui53z&amp;originHeight=808&amp;originWidth=1536&amp;originalType=binary%E2%88%B6=1&amp;rotation=0&amp;showTitle=false&amp;size=0&amp;status=done&amp;style=none&amp;title=&amp;width=1536" alt="" /></a><br />
本图主要解释了加入<code>Scaled</code>过程的原因，如上图中间的图像所示，蓝色是 QKTQKT，橙色是 softmax(QKT)softmax(QKT)，明显可以看出函数变的很尖，这样导致梯度变得很小，只有高数值的信息才会使模型更新，因此为了解决这个问题，在计算 softmax 之前除以 √dkdk。<br />
这里可以理解为两个独立的矩阵，均值为 0，方差为 1。经过矩阵相乘之后，均值还是 0，方差会变成 dkdk，这样就会导致 Softmax 之后梯度变得很小。<br />
<a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200413180003131.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981191232-6a6d2be0-4e0b-4f71-b201-3255af6d5801.png#height=812&amp;id=RdrBk&amp;originHeight=812&amp;originWidth=1468&amp;originalType=binary%E2%88%B6=1&amp;rotation=0&amp;showTitle=false&amp;size=0&amp;status=done&amp;style=none&amp;title=&amp;width=1468" alt="" /></a><br />
residual connection 是指经过一个 F(x)F(x)后，输出结果是 F(x)+xF(x)+x，这样做的目的是为了解决模型在多次进行 F(x)F(x)计算之后没有更多的<code>signore</code>的时候,模型可以弹性的选择哪部分要经过 F(x)F(x)，哪部分可以跳过 F(x)F(x)，而且模型也不需要更多的参数来进行训练。<br />
<a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200414151913660.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981192468-01860395-b3e6-4d10-a442-6b36575eeb33.png#height=804&amp;id=na2lw&amp;originHeight=804&amp;originWidth=1528&amp;originalType=binary%E2%88%B6=1&amp;rotation=0&amp;showTitle=false&amp;size=0&amp;status=done&amp;style=none&amp;title=&amp;width=1528" alt="" /></a><br />
在<code>Decoder</code>中，因为序列的预测过程是从左往右，所以右面单词的<code>Attention</code>是未知的，这就是绿色框中<code>Masked</code>与红色框之间有区别的原因。<br />
在蓝色框中，<code>Decoder</code>提供 Attention 的<code>Query</code>，<code>Encoder</code>提供 Attenion 的<code>Key</code>和<code>Query</code>。</p>
<h3 id="training-trick"><a class="markdownIt-Anchor" href="#training-trick"></a> Training Trick</h3>
<p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200414164511250.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981192403-78e67c1e-c92b-425f-b2ad-c2fec0ea0713.png#height=511&amp;id=rvLM9&amp;originHeight=511&amp;originWidth=1248&amp;originalType=binary%E2%88%B6=1&amp;rotation=0&amp;showTitle=false&amp;size=0&amp;status=done&amp;style=none&amp;title=&amp;width=1248" alt="" /></a></p>
<h4 id="byte-pair-encodings"><a class="markdownIt-Anchor" href="#byte-pair-encodings"></a> Byte-pair encodings</h4>
<p>BPE 算法的基本思路是把经常出现的<code>byte pair</code>用一个新的<code>byte</code>来代替，例如假设<code>('A', ’B‘）</code>经常顺序出现，则用一个新的标志<code>'AB'</code>来代替它们。<br />
例如，假设我们的文本库中出现的单词及其出现次数为<code>&#123;'l o w': 5, 'l o w e r': 2, 'n e w e s t': 6, 'w i d e s t': 3&#125;</code>，我们的初始词汇库为<code>&#123; 'l', 'o', 'w', 'e', 'r', 'n', 'w', 's', 't', 'i', 'd'&#125;</code>，出现频率最高的 ngram pair 是<code>('e','s')</code> 9 次，所以我们将’es’作为新的词汇加入到词汇库中，由于’es’作为一个整体出现在词汇库中，这时文本库可表示为 <code>&#123;'l o w': 5, 'l o w e r': 2, 'n e w es t': 6, 'w i d es t': 3&#125;</code>，这时出现频率最高的 ngram pair 是<code>('es','t')</code>9 次，将’est’加入到词汇库中，文本库更新为<code>&#123;'l o w': 5, 'l o w e r': 2, 'n e w est': 6, 'w i d est': 3&#125;</code>，新的出现频率最高的 ngram pair 是(‘l’,’o’)7 次，将’lo’加入到词汇库中，文本库更新为<code>&#123;'lo w': 5, 'lo w e r': 2, 'n e w est': 6, 'w i d est': 3&#125;</code>。以此类推，直到词汇库大小达到我们所设定的目标。这个例子中词汇量较小，对于词汇量很大的实际情况，我们就可以通过 BPE 逐步建造一个较小的基于 subword unit 的词汇库来表示所有的词汇。</p>
<h4 id="checkpoint-averaging"><a class="markdownIt-Anchor" href="#checkpoint-averaging"></a> Checkpoint averaging</h4>
<p>对训练过程中 checkpoint 保存的模型进行参数平均</p>
<h4 id="boom-search"><a class="markdownIt-Anchor" href="#boom-search"></a> Boom Search：</h4>
<ol>
<li><code>step 1</code>：在预测第一个单词的时候选择前<code>Beam width</code>个概率最大的单词作为第一个单词；</li>
<li><code>step 2</code>：假设词汇表长<code>10000</code>,<code>B=3</code>按照 P(y&lt;1&gt;,y&lt;2&gt;|x)=P(y&lt;1&gt;|x)P(y&lt;2&gt;|x,y&lt;1&gt;)P(y&lt;1&gt;,y&lt;2&gt;|x)=P(y&lt;1&gt;|x)P(y&lt;2&gt;|x,y&lt;1&gt;)最大，就会在开头为(y&lt;1&gt;,y&lt;2&gt;)(y&lt;1&gt;,y&lt;2&gt;)的<code>30000</code>种选择中选取概率最大的<code>3</code>种，并将(y&lt;1&gt;,y&lt;2&gt;)(y&lt;1&gt;,y&lt;2&gt;)作为新的开头；</li>
<li><code>step 3</code>：将<code>step 2</code>中选取的新的开头作为条件,重复计算<code>step 2</code>，如果遇到终止符则停止。</li>
</ol>
<p>改进集束搜索（改进其打分规则）：<br />
由于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="true"><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>a</mi><mi>x</mi><munderover><mo>∏</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>T</mi><mi>y</mi></msub></munderover><mi>P</mi><mo stretchy="false">(</mo><msup><mi>y</mi><mrow></mrow></msup><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">,</mo><msup><mi>y</mi><mn>1</mn></msup><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msup><mi>y</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">)</mo></mstyle></mrow><annotation encoding="application/x-tex">\displaystyle argmax \prod_{t=1}^{T_y}P(y^{}|x,y^{1},\dots,y^{t-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.2037690000000003em;vertical-align:-1.267113em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9366560000000004em;"><span style="top:-1.882887em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.4083250000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285716em;"><span style="top:-2.357em;margin-left:-0.13889em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2818857142857143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.267113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.413em;"><span style="top:-2.413em;margin-right:0.05em;"><span class="pstrut" style="height:2em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"></span></span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，是多个小于 1 的概率相乘，最终得到的数值会很小很小，出现数值下溢，因此对上述公式取对数：<br />
argmaxTy∑t=1log,P(y|x,y1,…,yt−1)argmax∑t=1Tylog,P(y|x,y1,…,yt−1)<br />
但是 log 函数在(0,1)是负数，序列越长数值越低，所以模型会更倾向于短文本输出而不是简洁的文本。于是第二次改进：<br />
1TαyTy∑t=1log,P(y|x,y1,…,yt−1)1Tyα∑t=1Tylog,P(y|x,y1,…,yt−1)<br />
对和函数进行归一化，但是不是单纯的除以单词数量，而是除以 TyTy 的 αα 次幂，这里的 αα 是一个超参数。</p>
<h3 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h3>
<ol>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV19g4y1b7vx?p=1">台大《应用深度学习》国语课程(2020) by 陈蕴侬</a></li>
<li><a target="_blank" rel="noopener" href="https://mooc.study.163.com/course/2001280005#/info">序列模型 by Andrew Ng</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/69414965">CS224N 笔记(十二):Subword 模型</a></li>
</ol>
	
		</div>
		
		<div id="current-post-cover" data-scr="/img/cart_cover.jpg"></div>

		<!-- relate post, comment...-->
		<div class="investment-container">
			<div class="investment-header">
				<div class="investment-title-1">
					<div class="on">相关文章</div>
					<div>评论</div>
					<div>分享</div>
				</div>
				<div class="investment-title-2">	            
					
	<span>
		<a id="totop-post-page">返回顶部</a>
		
			<a href="/2021/02/22/yuque/ecdpur/" title="你看不懂的BERT解读" rel="prev">
				&laquo;上一篇
			</a>
		
		
			<a href="/2021/01/28/yuque/xnw3ik/" title="Chrome自动将http切换为https" rel="next">
				下一篇&raquo;
			</a>
			
	</span>


      		
				</div>	
			</div>
			
			<div class="investment-content">
				<div class="investment-content-list">
					

<div class="relate-post">
	
		<ul>
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2021/02/22/yuque/qsv094/" title="使用PyTorch可视化必须知道的TensorBoard参数">
								使用PyTorch可视化必须知道的TensorBoard参数			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								二月 22日, 2021				
							</p>
							<p class="relate-post-content">
								亲测可用的PyTorch和TensorflowBoard版本，不会出现绘制模型结构图片时空白的情况。
1234torch==1.2.0tensorboard==2.1.1tensorflow==2.1.0tensorboardX==2...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2021/02/22/yuque/qsv094/" title="使用PyTorch可视化必须知道的TensorBoard参数">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="/img/cart_cover.jpg" alt="使用PyTorch可视化必须知道的TensorBoard参数"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2021/02/22/yuque/ecdpur/" title="你看不懂的BERT解读">
								你看不懂的BERT解读			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								二月 22日, 2021				
							</p>
							<p class="relate-post-content">
								本文主要是针对近年来序列模型的发展，例如 BERT、Transformer-XL、XLNet、RoBERTa 以及 XLM 等模型的思路整理。
 BERT: Bidirectional Encoder Representations ...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2021/02/22/yuque/ecdpur/" title="你看不懂的BERT解读">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="/img/cart_cover.jpg" alt="你看不懂的BERT解读"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2020/04/07/yuque/xcb5hp/" title="正则化">
								正则化			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								四月 7日, 2020				
							</p>
							<p class="relate-post-content">
								
模型越复杂越容易出现过拟合状态，所以需要一种机制来保证我们模型的“简单”，这样我们的模型才能有较好的泛化能力，正则化是这类机制之一。

欧几里得范数：
L2 范数：
L1 范数：

 推导过程

泰勒公式  

 为什么可以减少过拟...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2020/04/07/yuque/xcb5hp/" title="正则化">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="/img/cart_cover.jpg" alt="正则化"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2020/04/07/yuque/ehef5p/" title="机器学习常用算法原理">
								机器学习常用算法原理			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								四月 7日, 2020				
							</p>
							<p class="relate-post-content">
								 Logistic Regression
逻辑回归的假设函数：

其中是输入,是要求解的参数。
函数图像：

一个机器学习模型实际上是把决策函数限定在某组条件下，这组限定条件决定了模型的假设空间，逻辑回归的假设空间：

它的意思是在给...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2020/04/07/yuque/ehef5p/" title="机器学习常用算法原理">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="/img/cart_cover.jpg" alt="机器学习常用算法原理"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2024/01/08/yuque/wutni9yzkuq6y0n7/" title="《操作系统真象还原》：第十章 输入输出系统">
								《操作系统真象还原》：第十章 输入输出系统			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								一月 8日, 2024				
							</p>
							<p class="relate-post-content">
								
上一章中我们遇到的字符混乱和 GP 异常问题，根本原因是由于临界区代码的资源竞争，这需要一些互斥的方法来保证操作的原子性。

 10.1 同步机制——锁
 10.1.1 排查 GP 异常，理解原子操作
多线程执行刷屏时光标值越界导致...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2024/01/08/yuque/wutni9yzkuq6y0n7/" title="《操作系统真象还原》：第十章 输入输出系统">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="/img/cart_cover.jpg" alt="《操作系统真象还原》：第十章 输入输出系统"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2023/10/30/yuque/roml7fefy7cyczd4/" title="《操作系统真象还原》：第九章 线程">
								《操作系统真象还原》：第九章 线程			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								十月 30日, 2023				
							</p>
							<p class="relate-post-content">
								线程和进程将分两部分实现，本章先讲解线程。
 9.1 实现内核线程
 9.1.1 执行流
在处理器数量不变的情况下，多任务操作系统采用多道程序设计的方式，使处理器在所有任务之间来回切换，这称为“伪并行”，由操作系统中的任务调度器决定当...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2023/10/30/yuque/roml7fefy7cyczd4/" title="《操作系统真象还原》：第九章 线程">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="/img/cart_cover.jpg" alt="《操作系统真象还原》：第九章 线程"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2023/06/26/yuque/gflddumddhykfgqo/" title="GPU虚拟化">
								GPU虚拟化			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								六月 26日, 2023				
							</p>
							<p class="relate-post-content">
								
 用户层虚拟化
 本地 API 拦截和 API formwarding


在用户态实现一个函数库，假设叫 libwrapper， 它要实现底层库的所有 API；
让 APP 调用这个 libwrapper。如何做？
libwrap...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2023/06/26/yuque/gflddumddhykfgqo/" title="GPU虚拟化">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="/img/cart_cover.jpg" alt="GPU虚拟化"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2023/06/23/yuque/tgft5m5mgh787k7d/" title="硬件虚拟化">
								硬件虚拟化			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								六月 23日, 2023				
							</p>
							<p class="relate-post-content">
								 硬件虚拟化介绍
 硬件虚拟化要做的事情
 体系结构支持



体系结构
实现功能
作用




模式切换
Host CPU &lt;-&gt; Guest CPU 切换
CPU 资源隔离


二阶段地址转换
GVA-&gt; GPA...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2023/06/23/yuque/tgft5m5mgh787k7d/" title="硬件虚拟化">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="/img/cart_cover.jpg" alt="硬件虚拟化"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2023/01/20/yuque/dch1fprebtaxtqq8/" title="《操作系统真象还原》：第八章 内存管理系统">
								《操作系统真象还原》：第八章 内存管理系统			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								一月 20日, 2023				
							</p>
							<p class="relate-post-content">
								 8.1 makefile 简介

这部分可参考阮一峰的讲解：https://www.ruanyifeng.com/blog/2015/02/make.html

 8.1.1 makefile 是什么
makefile 是 Linu...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2023/01/20/yuque/dch1fprebtaxtqq8/" title="《操作系统真象还原》：第八章 内存管理系统">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="/img/cart_cover.jpg" alt="《操作系统真象还原》：第八章 内存管理系统"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/12/25/yuque/gf0t07d01kr4oe9r/" title="《操作系统真象还原》：第七章 中断">
								《操作系统真象还原》：第七章 中断			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								十二月 25日, 2022				
							</p>
							<p class="relate-post-content">
								 7.1 中断是什么，为什么要有中断
运用中断能够显著提升并发，从而大幅提升效率。
 7.2 操作系统是中断驱动的
略
 7.3 中断分类
把中断按事件来源分类，来自 CPU 外部的中断就称为外部中断，来自 CPU 内部的中断称为内部...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/12/25/yuque/gf0t07d01kr4oe9r/" title="《操作系统真象还原》：第七章 中断">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="/img/cart_cover.jpg" alt="《操作系统真象还原》：第七章 中断"/>
							</a>
						</div>
					</li>												
			
		</ul>
	
</div>	
				</div>
				<div class="investment-content-list">
					<div class="layout-comment">

	

		

			<!-- gitalk comment -->
			<!-- show gitalk comment -->
<div id="gitalk-container"></div>

<!-- gitalk`s css & js -->
<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<link rel="stylesheet" href="/css/comment.css">
<script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<script type="text/javascript">

	(function gitalkComment(){
		//Thanks O-R
		//https://github.com/gitalk/gitalk/issues/102#issuecomment-382970552
		//去除尾部匹配正则数组的字符串  
		//Remove redundant characters
		String.prototype.trimEnd = function(regStr) {
			let result = this;
			if(regStr == undefined || regStr == null || regStr == "") {
				return result;
			}
			let array = regStr.split(',');

			if(array.length > 0) {

				let c = array.shift(), 
					str = this,
					i = str.length,
					rg = new RegExp(c),
					matchArr = str.match(rg);

				if(matchArr != undefined && matchArr != null && matchArr.length > 0) {
					let matchStr = matchArr[0].replace(/\\/g, "\\\\").replace(/\*/g, "\\*")
						.replace(/\+/g, "\\+").replace(/\|/g, "\\|")
						.replace(/\{/g, "\\{").replace(/\}/g, "\\}")
						.replace(/\(/g, "\\(").replace(/\)/g, "\\)")
						.replace(/\^/g, "\\^").replace(/\$/g, "\\$")
						.replace(/\[/g, "\\[").replace(/\]/g, "\\]")
						.replace(/\?/g, "\\?").replace(/\,/g, "\\,")
						.replace(/\./g, "\\.").replace(/\&/g, "\\&");
					matchStr = matchStr + '$';
					result = str.replace(new RegExp(matchStr), "");
				}

				if(array.length > 0) {
					return result.trimEnd(array.join())
				} else {
					return result;
				}
			}
		};

		//Create gitalk
		let gitalk = new Gitalk({
			clientID: '693063c1941dbc1701d3',
			clientSecret: 'f88ddf502ef33ce91ce9d8c140dbc7e3a0653b7e',
			//id: window.location.pathname,
			//id: decodeURI(window.location.pathname),
			//id: (window.location.pathname).split("/").pop().substring(0, 49),
			id: decodeURI( md5( location.href.trimEnd('#.*$,\\?.*$,index.html$') ) ),
			repo: 'lisongqian.github.io',
			owner: 'lisongqian',
			admin: 'lisongqian',
			distractionFreeMode: 'false',
		})
		gitalk.render('gitalk-container');		
	})();
</script>

		
		
	

</div>
				</div>
				<div class="investment-content-list">
					<div class="layout-share">
	
	

		
			
			<!-- socialShare share -->
			<div class="social-share"></div>

<!--  css & js -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>
			
		
		
	
</div>


				</div>
			</div>	
		</div>
	</div>
</div>

<!-- show math formula -->



	





<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">


<script src="/plugin/fancybox/jquery.fancybox.js"></script>


<script type="text/javascript">
	(function gallerySet(){
		let titleID = $('.article-title a'),
			imageID = $('.article-content img'),
			videoID = $('.article-content video');
		
		let postTitle = titleID.text() ? titleID.text() : "No post title!";
		
		imageID.each(function() {
			let imgPath = $(this).attr('src'),
				imgTitle = $(this).attr('alt') ? $(this).attr('alt') : "No image description!";
		
			//给每个匹配的<img>元素打包, 即添加父元素<a>
			$(this).wrap('<a data-fancybox="gallery" data-caption="《 ' + postTitle + ' 》' + imgTitle + '"href="' + imgPath + '"> </a>');
		});
		
		videoID.each(function() {
			let videoPath = $(this).attr('src');
		
			//给每个匹配的<img>元素打包, 即添加父元素<a>
			$(this).wrap('<a data-fancybox href=" ' + videoPath + ' "> </a>');
		});
		
		//TODO：支持html5 video

		if($('#layout-post').length) {
			$('[data-fancybox="gallery"]').fancybox({
				loop: true,
				buttons: [
					"zoom",
					"share",
					"slideShow",
					"fullScreen",
					//"download",
					"thumbs",
					"close"
				],
				protect: true
			});
		}
	})();
</script>
		</main>

		<!--footer-->
		<footer>
	<div id="navigation-show">
		<ul id="global-nav">
	
		<li class="menu-home">
			<a href="/" class="menu-item-home" target="_blank">主页</a>
		</li>
		
	
		<li class="menu-archive">
			<a href="/archives" class="menu-item-archive" target="_blank">归档</a>
		</li>
		
	
		<li class="menu-categories">
			<a href="/categories" class="menu-item-categories" target="_blank">分类</a>
		</li>
		
	
		<li class="menu-tags">
			<a href="/tags" class="menu-item-tags" target="_blank">标签</a>
		</li>
		
	
		<li class="menu-about">
			<a href="/about" class="menu-item-about" target="_blank">关于</a>
		</li>
		
	

	
		<li class="menu-search">
			<a href="javascript:;" class="popup-trigger">搜索</a>
		</li>
	
</ul>
	</div>

	<div class="copyright">
		<p>
		<a href="http://www.beian.miit.gov.cn/" target="_blank" rel="noopener">鲁ICP备16042410号</a>
			 
				&copy;2017 - 2024, content by SongqianLi. All Rights Reserved.
			
			
				<a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> Theme <a href="https://github.com/Sariay/hexo-theme-Annie" title="Annie" target="_blank" rel="noopener">Annie</a> by Sariay.
			
		</p>
		<p>
			

	<!-- busuanzi -->
	<!-- busuanzi -->



			<a href="javascript:zh_tran('s');" class="zh_click" id="zh_click_s">简体</a> 
			<a href="javascript:zh_tran('t');" class="zh_click" id="zh_click_t">繁體</a>				
		</p>
	</div>		
</footer>
		

<!-- love effect -->


<!-- back to top -->

	<div id="totop">
	<span class="icon-circle-up"></span>
</div>




<!-- leancloud -->


	<!-- leancloud -->
	<!--
	时间：2018-11-27
	描述：
		文章访问量：visitors
		文章喜欢量：likes	
		文章排行榜：topNPost
		其他得说明：
			01-Cookie相关的函数 
				https://blog.csdn.net/somehow1002/article/details/78511541（Author：somehow1002）
			02-visitors相关的函数 
				https://blog.csdn.net/u013553529/article/details/63357382（Author：爱博客大伯）
				https://notes.doublemine.me/2015-10-21-为NexT主题添加文章阅读量统计功能.html（Author：夏末）
			03-topNPost相关的函数
				https://hoxis.github.io/hexo-next-read-rank.html（Author：hoxis）
			04-likes相关的函数，
				参考了01 & 02进行简单的设计与实现
-->


	

  

	<!--
	时间：2018-10-3
	描述：
		插件名称：hexo-generator-search-zip
		插件来源: https://github.com/SuperKieran/hexo-generator-search-zip
		代码参考：https://github.com/SuperKieran/TKL/blob/master/layout/_partial/search.ejs(Include: js & css)	
-->
<div class="popup search-popup local-search-popup scrollbar" >
	<div class="local-search-container">
		<span class="popup-btn-close">
      		ESC
   		</span>
		<div class="local-search-header">
			<div class="input-prompt">				
			</div>
			<input autocomplete="off" placeholder="Search..." type="text" id="local-search-input">
		</div>
		<div class="local-search-body">
			<div id="local-search-output"></div>
		</div>
		<div class="local-search-footer">
			<div class="topN-post">				
				
								
			</div>
		</div>
	</div>
</div>


<script src="/plugin/search/ziploader.js"></script>
<script src="/js/search.js"></script>


<script type="text/javascript">
	var search_path = 'search.json',
		zip_Path = '/search.zip',
		version_Path = '/searchVersion.txt',
		input_Trigger = 'auto',
		top_N = '2';

	themeLocalSearch({
		search_path, 
		zip_Path, 
		version_Path, 
		input_Trigger, 
		top_N
	});
</script>



<script src="/plugin/chinese/chinese.js"></script>
<script src="/plugin/imagelazyloader/yall.min.js"></script>
<script src="/plugin/imageloaded/imagesloaded.pkgd.min.js"></script>
<script src="/plugin/resizediv/resizediv.js"></script>
<script src="/js/main.js"></script>

	</body>	
</html>