<!--
	作者：Sariay
	时间：2018-08-26
	描述：There may be a bug, but don't worry, Qiling(器灵) says that it can work normally! aha!
-->
<!DOCTYPE html>
<html class="html-loading">
		

<head>
	<meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
  <title>
    
      你看不懂的BERT解读 | Songqian Li&#39;s Blog
    
  </title>
  <meta name="author" content="Songqian Li">
  <meta name="keywords" content="" />
  <meta name="description" content="C U" />
	<!-- favicon -->
  <link rel="shortcut icon" href="/img/favicon.ico">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Playfair+Display:400,700,900">
  <!-- css -->
  
<link rel="stylesheet" href="/css/Annie.css">

  
  <!-- jquery -->
	
<script src="/plugin/jquery/jquery.min.js"></script>


<script>
    const CONFIG_BGIMAGE = {
      mode: 'normal',
      normalSrc: 'https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/header-bg.jpg',
      randomYouMax: 110,
      randomYouSrc: 'https://sariay.github.io/Random-img/',
	  randomOtherSrc: 'https://api.berryapi.net/?service=App.Bing.Images&day=-0',
	  preloaderEnable: false
    }
	
    const CONFIG_LEACLOUD_COUNT = {
      enable: true,
	  appId: 'L0W62cCkHAgT0VsIX6WztMhp-gzGzoHsz',
	  appKey: 'n1lX9eWfotXltQ6Cab3ngGfk',
	  serverURLs: 'https://l0w62cck.lc-cn-n1-shared.com' || ' '
    }
  </script>
  <!-- site analysis -->
  

	<!-- site-analysis -->
	
	<script>
		var _hmt = _hmt || [];
		(function() {
			var hm = document.createElement("script");
			hm.src = "//hm.baidu.com/hm.js?b702b9b0aa72233c214dcbade17a5a27";
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(hm, s);
		})();
	</script>

	
	
	
	
 
    <meta name="referrer" content="no-referrer"/>
<meta name="generator" content="Hexo 6.2.0"></head>
	<body>
		<!-- Preloader -->


<!-- header -->
<header class="fixbackground">
		<div class="header-wrapper">
		<ul id="global-nav">
	
		<li class="menu-home">
			<a href="/" class="menu-item-home" target="_blank">主页</a>
		</li>
		
	
		<li class="menu-archive">
			<a href="/archives" class="menu-item-archive" target="_blank">归档</a>
		</li>
		
	
		<li class="menu-categories">
			<a href="/categories" class="menu-item-categories" target="_blank">分类</a>
		</li>
		
	
		<li class="menu-tags">
			<a href="/tags" class="menu-item-tags" target="_blank">标签</a>
		</li>
		
	
		<li class="menu-about">
			<a href="/about" class="menu-item-about" target="_blank">关于</a>
		</li>
		
	

	
		<li class="menu-search">
			<a href="javascript:;" class="popup-trigger">搜索</a>
		</li>
	
</ul>
	</div>
	<div class="mask">
	<div class="banner-frame border-image" style="border-image-source: url('https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/mask.png');"></div>
		<div class="container">
			<div class="row">
				<div class="col-md-12">
					<div class="align">
						<h1 class="h1 light">Songqian Li&#39;s Blog</h1>
						<div class="empty-space col-xs-b15"></div>
						<div class="sa light large">C U</div>
						<div class="empty-space col-xs-b30"></div>
					</div>
				</div>
			</div>
		</div>
		<!-- motto -->
		<div class="h-body">	
			
		</div>
		
		<!-- others: such as time... -->			
		<div class="h-footer">
			<a href="javascript:;" id="read-more" class="scroll-down">
				<span class="icon-anchor1 animation-scroll-down"></span>
			</a>
		</div>
	</div>
</header>

<div id="navigation-hide">
	<!-- Progress bar -->
	<div id="progress-bar"></div>

	<!-- Progress percent -->
	<div id="progress-percentage"><span>0.0%</span></div>

	<div class="toc-switch"><span class="switch-button">目录</span></div>

	<!-- Page title -->
	<p>
		
			「你看不懂的BERT解读」
		
	</p>

	
	

	<!-- Nav trigger for navigation-H-->
	<a class="nav-trigger"><span></span></a>
</div>

<!-- Navigation in div(id="navigation-H") -->
<nav class="nav-container" id="cd-nav">
	<div class="nav-header">
		<!--<span class="logo"> 
			<img src="/img/logo.png">
		</span> -->
		<a href="javascript:;" class="nav-close"></a>
	</div>
	
	<div class="nav-body">
		<ul id="global-nav">
	
		<li class="menu-home">
			<a href="/" class="menu-item-home" target="_blank">主页</a>
		</li>
		
	
		<li class="menu-archive">
			<a href="/archives" class="menu-item-archive" target="_blank">归档</a>
		</li>
		
	
		<li class="menu-categories">
			<a href="/categories" class="menu-item-categories" target="_blank">分类</a>
		</li>
		
	
		<li class="menu-tags">
			<a href="/tags" class="menu-item-tags" target="_blank">标签</a>
		</li>
		
	
		<li class="menu-about">
			<a href="/about" class="menu-item-about" target="_blank">关于</a>
		</li>
		
	

	
		<li class="menu-search">
			<a href="javascript:;" class="popup-trigger">搜索</a>
		</li>
	
</ul>
	</div>
	
	<div class="nav-footer">
		<ul id="global-social">
	
		<li>
			<a href="//github.com/lisongqian" target="_blank">
				<span class="icon-github"></span>
			</a>
		</li>
	
		<li>
			<a href="/atom.xml" target="_blank">
				<span class="icon-rss"></span>
			</a>
		</li>
			
</ul>

	</div>
</nav>
			
		<!--main-->
		<main>
			<!--
	时间：2018-11-17
	描述：
		插件名称：katelog.min.js
		插件作者：KELEN
		插件来源: https://github.com/KELEN/katelog
-->
	 

<div class="layout-post">
	<div id="layout-post">
		<div class="article-title">
			
	<a href="/2021/02/22/yuque/ecdpur/" itemprop="url">
		你看不懂的BERT解读
	</a>

		</div>

		<div class="article-meta">
			<span>
				<i class="icon-calendar1"></i>
				
				




	更新于

	<a href="/2021/02/22/yuque/ecdpur/" itemprop="url">
		<time datetime="2021-02-22T08:08:15.000Z" itemprop="dateUpdated">
	  		2022-06-29
	  </time>
	</a> 



			</span>
			<span>
				
	<i class="icon-price-tags"></i>
	
		<a href="/tags/MachineLearning/" class=" ">
			MachineLearning
		</a>
	
		<a href="/tags/BERT/" class=" ">
			BERT
		</a>
	
		
			</span>
			
			



		</div>

		<div class="article-content" id="article-content">
			<p>本文主要是针对近年来序列模型的发展，例如 BERT、Transformer-XL、XLNet、RoBERTa 以及 XLM 等模型的思路整理。</p>
<h2 id="BERT-Bidirectional-Encoder-Representations-from-Transformers"><a href="#BERT-Bidirectional-Encoder-Representations-from-Transformers" class="headerlink" title="BERT: Bidirectional Encoder Representations from Transformers"></a>BERT: Bidirectional Encoder Representations from Transformers</h2><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200415190625530.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445189-30791861-56d7-49e8-b8fb-b2b244565005.png#crop=0&crop=0&crop=1&crop=1&height=834&id=Q1sAi&originHeight=834&originWidth=1486&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1486"></a><br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200415192917464.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445306-3d6a58df-20d9-4866-9919-8a8fcf4c6f52.png#crop=0&crop=0&crop=1&crop=1&height=804&id=B6xbe&originHeight=804&originWidth=1183&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1183"></a><br>上图是 BERT 提出的主要的两个点。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200416094110056.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445106-4d502e12-a548-4181-ae19-43a98aedea3f.png#crop=0&crop=0&crop=1&crop=1&height=831&id=yQ4tI&originHeight=831&originWidth=1483&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1483"></a><br>选择<code>encoder</code>哪一层的信息会比较好呢？上图给出了解答。不难看出，后四层的<code>encoder</code>层<code>sum</code>之后得到了当前维度的最高<code>F1</code>，而<code>concat</code>后四层发现<code>F1</code>又有所提高，所以综合来看选择<code>encoder</code>的后几层的效果会比较好。</p>
<h2 id="Transformer-XL"><a href="#Transformer-XL" class="headerlink" title="Transformer-XL"></a>Transformer-XL</h2><p>超长输入的文本会被原始的 transformer 切掉，而且如果进行切分的时候也没有很好的解决切分的边界问题。<code>Transformer-XL</code>就是要解决这个问题。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/transformerxl.gif"><img src="https://cdn.nlark.com/yuque/0/2021/gif/1249968/1613981445221-fc7ecb03-c7e1-4274-b9f2-a25651968e47.gif#crop=0&crop=0&crop=1&crop=1&height=396&id=FcIm5&originHeight=396&originWidth=794&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=794"></a><br><code>Tranformer-XL</code>的解决方式如上图所示，在训练下一个<code>segment</code>时，从上一个<code>segment</code>读取参数进行重用，这样可以使得<code>dependency</code>的长度可以扩展到<code>N</code>倍，<code>N</code>是神经网络的深度。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200416110929660.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445229-eca05f9f-50f4-4dee-ab3f-3255781a7a32.png#crop=0&crop=0&crop=1&crop=1&height=802&id=kL8mS&originHeight=802&originWidth=1484&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1484"></a><br>模型优点的比较：在<code>Vanilla</code>版本<code>Train phase</code>时，两个<code>segment</code>是互相独立的，在跨越两个<code>seqment</code>的<code>dependency</code>就没有被考虑；而在<code>Evaluation</code>时，如果要输出的长度为 6，而学习的一个<code>segment</code>只有 4 的时候，就会出现预测的序列只能看到前后 4 个点的权值。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200416160316230.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445315-3b3bfb23-08e0-4d41-8927-edd631454b20.png#crop=0&crop=0&crop=1&crop=1&height=770&id=PUDTU&originHeight=770&originWidth=1484&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1484"></a><br>让模型去考虑相对位置的关系，而不是绝对位置的关系。ExiExi 是<code>word embedding</code>，UiUi 是<code>position embedding</code>，在相对位置关系中会选定一个基准点作为基准向量 uTuT、vTvT,然后用 Ri−jRi−j 来表示 i,ji,j 两个位置之间的差异，这里 uT,vT,Ri−juT,vT,Ri−j 都是需要训练的。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200416160837907.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445289-88232a7b-4219-4409-af9b-8cfa25bee53a.png#crop=0&crop=0&crop=1&crop=1&height=562&id=iJHs8&originHeight=562&originWidth=1495&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1495"></a></p>
<h2 id="XLNet：Generalized-Autoregressive-Pretraining-for-Language-Understanding"><a href="#XLNet：Generalized-Autoregressive-Pretraining-for-Language-Understanding" class="headerlink" title="XLNet：Generalized Autoregressive Pretraining for Language Understanding"></a>XLNet：Generalized Autoregressive Pretraining for Language Understanding</h2><p>在说 XLNet 之前要先提一下 AR 和 AE 模型的概念。</p>
<h3 id="Auto-Regressive-AR"><a href="#Auto-Regressive-AR" class="headerlink" title="Auto-Regressive(AR)"></a>Auto-Regressive(AR)</h3><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200416204425838.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445391-1854e5a8-a984-4c97-a0c6-5ae03362504f.png#crop=0&crop=0&crop=1&crop=1&height=759&id=bTDUo&originHeight=759&originWidth=1508&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1508"></a><br>模型在预测 XtXt 的时候，只会看到前半部分或者后半部分考虑的<code>information</code>。</p>
<h3 id="Auto-Encoding-AE"><a href="#Auto-Encoding-AE" class="headerlink" title="Auto-Encoding(AE)"></a>Auto-Encoding(AE)</h3><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200416205713669.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445306-23eb2886-f2a6-455d-94b2-09574a18266a.png#crop=0&crop=0&crop=1&crop=1&height=841&id=zpXJU&originHeight=841&originWidth=1402&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1402"></a><br>从一个有<code>noise</code>的样本预测原本的值，是可以看到左右两部分的信息。<br>AE 存在的问题是：</p>
<ol>
<li>AE 模型认为不同位置的<code>[MASK]</code>是互相独立的，认为模型预测前一个<code>[MASK]</code>的词不会影响到后一个<code>[MASK]</code>，但是实际上是有可能两个位置的<code>[MASK]</code>互相关联。</li>
<li>在<code>pre-training</code>和<code>fine-tuning</code>之间存在差异。具体表现在<code>pre-training</code>过程中有<code>[MASK]</code>标签，而在<code>fine-tuning</code>过程中是没有<code>[MASK]</code>的，这就存在了一种<code>input noise</code>的情况。</li>
</ol>
<h3 id="XLNet"><a href="#XLNet" class="headerlink" title="XLNet"></a>XLNet</h3><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200416211234288.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445298-1780d594-d845-4916-83fa-5ad91b477fe3.png#crop=0&crop=0&crop=1&crop=1&height=805&id=jumgb&originHeight=805&originWidth=1503&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1503"></a><br>XLNet 目标是使用 AR 模型，但同时也能够使用<code>bidirectional contexts</code>。方法是随机排列这段<code>sequence</code>的每个单词，让模型去学习每个随机后的<code>sequence</code>，这样在第 tt 个位置之后的信息也有可能随机到 tt 前面而被模型学习到。<br>例如图中三种情况：</p>
<ol>
<li>序列为<code>3-2-4-1</code>：以 3 为例，此时 3 为开头，模型只能看到起始符，看不到其他任何符号；</li>
<li>序列为<code>2-4-3-1</code>：以 3 为例，此时 3 可以看到 2 和 4；</li>
<li>序列为<code>1-4-2-3</code>：以 3 为例，此时可以看到序列的全部其他信息(1,4,2)。</li>
</ol>
<h4 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h4><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200416212906233.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445237-eb30a06b-6666-4d70-b9f9-ce32b14f755d.png#crop=0&crop=0&crop=1&crop=1&height=828&id=ID0Z4&originHeight=828&originWidth=1448&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1448"></a><br>上述的乱序过程实质上就是改变了每个节点的<code>Attention</code>可以看到哪些节点的信息，也就是改变了<code>Attention mask</code>矩阵的值。因此在实现<code>Positional Encoding</code>时，没有打乱 x1,…,x4x1,…,x4 的顺序，而是将每个节点可以看到的信息依次填入了正常的<code>Positional Encoding</code>矩阵。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200417093522502.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445325-40f127d3-3a19-45f3-ac48-9f953d6b3379.png#crop=0&crop=0&crop=1&crop=1&height=783&id=CM0Fq&originHeight=783&originWidth=1508&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1508"></a><br>但是实现这种随机乱序存在的问题是模型不知道 P(x3|x1,x2)P(x3|x1,x2)和 P(x4|x1,x2)P(x4|x1,x2)的区别，模型不知道预测的下一个<code>token</code>是第三个位置的还是第四个位置的，为了解决这个问题就引入了<code>Two-Stream Self-Attnetion</code>来引入<code>position</code>信息 ztzt。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200417145435974.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445207-80136a05-2453-4dcb-86d8-0e1edf50f9ff.png#crop=0&crop=0&crop=1&crop=1&height=851&id=RH6lY&originHeight=851&originWidth=1523&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1523"></a><br>两个<code>Stream</code>分别是能看到自身的<code>Content stream</code>hh 和不能看到自身的<code>Query stream</code>gg。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200417150044950.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445217-3d7390ba-5f09-4ee0-8ed0-339abc758cc9.png#crop=0&crop=0&crop=1&crop=1&height=842&id=xPCAf&originHeight=842&originWidth=1518&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1518"></a><br>上图能够更清楚的展示出<code>Content stream</code>和<code>Query stream</code>的区别。最终模型在<code>pre-training</code>阶段时，因为<code>sequence</code>中存在<code>[MASK]</code>，所以就使用<code>Query stream</code>来学习信息；在<code>fine-tuning</code>时由于可以看到所有的输入所以就使用<code>Content stream</code>。<br>个人理解：XLNet 利用两种<code>Attention</code>来解决<code>pre-training</code>和<code>fine-tuning</code>阶段中存在的<code>input noise</code>问题，在预测<code>[MASK]</code>位置的信息时使用<code>Query stream</code>，在预测其他位置的信息时使用<code>Content stream</code>。<br><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200417151803301.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445495-441addb8-a57b-4d4b-9c6d-7a7aee1bdd3a.png#crop=0&crop=0&crop=1&crop=1&height=596&id=tMHCZ&originHeight=596&originWidth=1227&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1227"></a></p>
<h2 id="RoBERTa：A-Robustly-Optimized-BERT-Pretraining-Approach"><a href="#RoBERTa：A-Robustly-Optimized-BERT-Pretraining-Approach" class="headerlink" title="RoBERTa：A Robustly Optimized BERT Pretraining Approach"></a>RoBERTa：A Robustly Optimized BERT Pretraining Approach</h2><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200417174121038.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445348-f3b7d777-b0f1-47f0-b17e-3e5c9a6f7380.png#crop=0&crop=0&crop=1&crop=1&height=783&id=RWbzE&originHeight=783&originWidth=1508&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1508"></a></p>
<h4 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions:"></a>Contributions:</h4><ol>
<li>pre-training 使用十次不同的 mask 结果；</li>
<li>调参；</li>
<li><strong>增大数据量，只训练完整的序列。</strong>（个人感觉最大的优点，数据量大）<blockquote>
<p>下面是 BERT 模型的其他变种：</p>
</blockquote>
</li>
</ol>
<h2 id="SpanBERT-Improving-Pre-training-by-Representing-and-Predicting-Spans"><a href="#SpanBERT-Improving-Pre-training-by-Representing-and-Predicting-Spans" class="headerlink" title="SpanBERT: Improving Pre-training by Representing and Predicting Spans"></a>SpanBERT: Improving Pre-training by Representing and Predicting Spans</h2><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200417201831583.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445464-073ffbfa-4fb0-49d1-943d-21113c91daf6.png#crop=0&crop=0&crop=1&crop=1&height=832&id=PbvuY&originHeight=832&originWidth=1520&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1520"></a></p>
<h2 id="XLM-Enhancing-BERT-for-Cross-lingual-Language-Model"><a href="#XLM-Enhancing-BERT-for-Cross-lingual-Language-Model" class="headerlink" title="XLM: Enhancing BERT for Cross-lingual Language Model"></a>XLM: Enhancing BERT for Cross-lingual Language Model</h2><p><a target="_blank" rel="noopener" href="http://cdn.lisongqian.cn/img/image-20200417202929428.png"><img src="https://cdn.nlark.com/yuque/0/2021/png/1249968/1613981445416-17bef0fc-6843-48d9-8702-47b058eaa319.png#crop=0&crop=0&crop=1&crop=1&height=837&id=ZmeYX&originHeight=837&originWidth=1313&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=0&status=done&style=none&title=&width=1313"></a></p>
<h3 id="REFERENCE"><a href="#REFERENCE" class="headerlink" title="REFERENCE"></a>REFERENCE</h3><p><a target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2019-05-29">Facebook AI Research 的 XLM 模型：将 BERT 扩展成跨语言模型</a><br><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV19g4y1b7vx?p=36">台大《应用深度学习》国语课程(2020) by 陈蕴侬</a></p>
	
		</div>
		
		<div id="current-post-cover" data-scr="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg"></div>

		<!-- relate post, comment...-->
		<div class="investment-container">
			<div class="investment-header">
				<div class="investment-title-1">
					<div class="on">相关文章</div>
					<div>评论</div>
					<div>分享</div>
				</div>
				<div class="investment-title-2">	            
					
	<span>
		<a id="totop-post-page">返回顶部</a>
		
			<a href="/2021/02/22/yuque/qsv094/" title="使用PyTorch可视化必须知道的TensorBoard参数" rel="prev">
				&laquo;上一篇
			</a>
		
		
			<a href="/2021/02/22/yuque/aih1sz/" title="我发现了Transformer模型的秘密" rel="next">
				下一篇&raquo;
			</a>
			
	</span>


      		
				</div>	
			</div>
			
			<div class="investment-content">
				<div class="investment-content-list">
					

<div class="relate-post">
	
		<ul>
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2021/02/22/yuque/qsv094/" title="使用PyTorch可视化必须知道的TensorBoard参数">
								使用PyTorch可视化必须知道的TensorBoard参数			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								二月 22日, 2021				
							</p>
							<p class="relate-post-content">
								亲测可用的PyTorch和TensorflowBoard版本，不会出现绘制模型结构图片时空白的情况。
1234torch==1.2.0tensorboard==2.1.1tensorflow==2.1.0tensorboardX==2...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2021/02/22/yuque/qsv094/" title="使用PyTorch可视化必须知道的TensorBoard参数">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="使用PyTorch可视化必须知道的TensorBoard参数"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2021/02/22/yuque/aih1sz/" title="我发现了Transformer模型的秘密">
								我发现了Transformer模型的秘密			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								二月 22日, 2021				
							</p>
							<p class="relate-post-content">
								本文希望从 Base-Attention 到 Transformer 逐层递进的解释其中的计算细节,从而更好的理解 Transformer 模型。本文主要对模型可能存在的盲区进行解释，可能思路有些跳跃，请谅解。参考资料见文章末尾Ref...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2021/02/22/yuque/aih1sz/" title="我发现了Transformer模型的秘密">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="我发现了Transformer模型的秘密"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2020/04/07/yuque/xcb5hp/" title="正则化">
								正则化			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								四月 7日, 2020				
							</p>
							<p class="relate-post-content">
								
模型越复杂越容易出现过拟合状态，所以需要一种机制来保证我们模型的“简单”，这样我们的模型才能有较好的泛化能力，正则化是这类机制之一。

欧几里得范数：
L2 范数：
L1 范数：

推导过程
泰勒公式  

为什么可以减少过拟合
直...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2020/04/07/yuque/xcb5hp/" title="正则化">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="正则化"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2020/04/07/yuque/ehef5p/" title="机器学习常用算法原理">
								机器学习常用算法原理			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								四月 7日, 2020				
							</p>
							<p class="relate-post-content">
								Logistic Regression逻辑回归的假设函数：

其中是输入,是要求解的参数。
函数图像：

一个机器学习模型实际上是把决策函数限定在某组条件下，这组限定条件决定了模型的假设空间，逻辑回归的假设空间：

它的意思是在给定的...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2020/04/07/yuque/ehef5p/" title="机器学习常用算法原理">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="机器学习常用算法原理"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/06/28/yuque/tgf3hu/" title="Project-C社区Linux Kernel编译">
								Project-C社区Linux Kernel编译			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								六月 28日, 2022				
							</p>
							<p class="relate-post-content">
								下载源代码下载 kernel 源代码，默认为 5.15-lts 分支
1git clone https://gitlab.com/songqianli/linux-prjc.git

安装软件包1sudo apt-get instal...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/06/28/yuque/tgf3hu/" title="Project-C社区Linux Kernel编译">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="Project-C社区Linux Kernel编译"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/06/16/yuque/dlziqz/" title="6月阅读总结">
								6月阅读总结			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								六月 16日, 2022				
							</p>
							<p class="relate-post-content">
								
“零拷贝”技术
Sogou C++ Workflow：搜狗公司的 C++服务器引擎，支持 500k QPS
Reducing CPU scheduler latency in Linux：CPU 调度算法 BMQ 和 CFS 的对比...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/06/16/yuque/dlziqz/" title="6月阅读总结">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="6月阅读总结"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/05/23/yuque/bfwmot/" title="《操作系统真象还原》：第2章 编写 MBR">
								《操作系统真象还原》：第2章 编写 MBR			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								五月 23日, 2022				
							</p>
							<p class="relate-post-content">
								先了解 CPU 的两种工作模式：实模式和保护模式实模式（英语：Real mode）是 Intel 80286 和之后的 x86 兼容 CPU 的操作模式。实模式的特性是一个 20 比特的区段存储器地址空间（意思为只有 1MB 的存储器...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/05/23/yuque/bfwmot/" title="《操作系统真象还原》：第2章 编写 MBR">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="《操作系统真象还原》：第2章 编写 MBR"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/05/10/yuque/ouqh35/" title="五月阅读总结">
								五月阅读总结			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								五月 10日, 2022				
							</p>
							<p class="relate-post-content">
								
eBPF 技术简介
基于 eBPF 的网络检测实践
Chapter 2. Debian package management



2.1.6. Package dependencies
The Debian system offe...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/05/10/yuque/ouqh35/" title="五月阅读总结">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="五月阅读总结"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/05/09/yuque/wx4152/" title="《操作系统真象还原》：第1章 环境配置">
								《操作系统真象还原》：第1章 环境配置			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								五月 9日, 2022				
							</p>
							<p class="relate-post-content">
								第 0 章：一些你可能正感到迷惑的问题
摘记

0.28 MBR、EBR、DBR 和 OBR 各是什么MBR 位于整个硬盘最开始的块， EBR 位于每个子扩展分区，各子扩展分区中只有一个逻辑分区。 MBR 和 EBR 位于分区之外的扇...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/05/09/yuque/wx4152/" title="《操作系统真象还原》：第1章 环境配置">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="《操作系统真象还原》：第1章 环境配置"/>
							</a>
						</div>
					</li>												
			
					<li>
						<div class="relate-post-text">
							<a class="relate-post-title" href="/2022/05/05/yuque/to6mm2/" title="为什么Proactor比Reactor模式更优？">
								为什么Proactor比Reactor模式更优？			
							</a>
							<p class="relate-post-date">
								<i class="fa fa-calendar"></i>
								五月 5日, 2022				
							</p>
							<p class="relate-post-content">
								首先，我们先了解一下什么是 Reactor 模式和 Proactor 模式。
什么是 Reactor 模式和 Proactor 模式？Reactor 模式Reactor 模式是指主线程负责监听和分发事件，工作线程负责 I&#x2F;O...
							</p>
						</div>

						<div class="relate-post-cover">
							<a href="/2022/05/05/yuque/to6mm2/" title="为什么Proactor比Reactor模式更优？">				
								
								<img class="lazy" src="/img/lazy.gif" data-src="https://cdn.jsdelivr.net/gh/lisongqian/lisongqian.github.io@master/img/cart_cover.jpg" alt="为什么Proactor比Reactor模式更优？"/>
							</a>
						</div>
					</li>												
			
		</ul>
	
</div>	
				</div>
				<div class="investment-content-list">
					<div class="layout-comment">

	

		

			<!-- gitalk comment -->
			<!-- show gitalk comment -->
<div id="gitalk-container"></div>

<!-- gitalk`s css & js -->
<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<link rel="stylesheet" href="/css/comment.css">
<script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<script type="text/javascript">

	(function gitalkComment(){
		//Thanks O-R
		//https://github.com/gitalk/gitalk/issues/102#issuecomment-382970552
		//去除尾部匹配正则数组的字符串  
		//Remove redundant characters
		String.prototype.trimEnd = function(regStr) {
			let result = this;
			if(regStr == undefined || regStr == null || regStr == "") {
				return result;
			}
			let array = regStr.split(',');

			if(array.length > 0) {

				let c = array.shift(), 
					str = this,
					i = str.length,
					rg = new RegExp(c),
					matchArr = str.match(rg);

				if(matchArr != undefined && matchArr != null && matchArr.length > 0) {
					let matchStr = matchArr[0].replace(/\\/g, "\\\\").replace(/\*/g, "\\*")
						.replace(/\+/g, "\\+").replace(/\|/g, "\\|")
						.replace(/\{/g, "\\{").replace(/\}/g, "\\}")
						.replace(/\(/g, "\\(").replace(/\)/g, "\\)")
						.replace(/\^/g, "\\^").replace(/\$/g, "\\$")
						.replace(/\[/g, "\\[").replace(/\]/g, "\\]")
						.replace(/\?/g, "\\?").replace(/\,/g, "\\,")
						.replace(/\./g, "\\.").replace(/\&/g, "\\&");
					matchStr = matchStr + '$';
					result = str.replace(new RegExp(matchStr), "");
				}

				if(array.length > 0) {
					return result.trimEnd(array.join())
				} else {
					return result;
				}
			}
		};

		//Create gitalk
		let gitalk = new Gitalk({
			clientID: '693063c1941dbc1701d3',
			clientSecret: 'f88ddf502ef33ce91ce9d8c140dbc7e3a0653b7e',
			//id: window.location.pathname,
			//id: decodeURI(window.location.pathname),
			//id: (window.location.pathname).split("/").pop().substring(0, 49),
			id: decodeURI( md5( location.href.trimEnd('#.*$,\\?.*$,index.html$') ) ),
			repo: 'lisongqian.github.io',
			owner: 'lisongqian',
			admin: 'lisongqian',
			distractionFreeMode: 'false',
		})
		gitalk.render('gitalk-container');		
	})();
</script>

		
		
	

</div>
				</div>
				<div class="investment-content-list">
					<div class="layout-share">
	
	

		
			
			<!-- socialShare share -->
			<div class="social-share"></div>

<!--  css & js -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>
			
		
		
	
</div>


				</div>
			</div>	
		</div>
	</div>
</div>

<!-- show math formula -->



	





<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">


<script src="/plugin/fancybox/jquery.fancybox.js"></script>


<script type="text/javascript">
	(function gallerySet(){
		let titleID = $('.article-title a'),
			imageID = $('.article-content img'),
			videoID = $('.article-content video');
		
		let postTitle = titleID.text() ? titleID.text() : "No post title!";
		
		imageID.each(function() {
			let imgPath = $(this).attr('src'),
				imgTitle = $(this).attr('alt') ? $(this).attr('alt') : "No image description!";
		
			//给每个匹配的<img>元素打包, 即添加父元素<a>
			$(this).wrap('<a data-fancybox="gallery" data-caption="《 ' + postTitle + ' 》' + imgTitle + '"href="' + imgPath + '"> </a>');
		});
		
		videoID.each(function() {
			let videoPath = $(this).attr('src');
		
			//给每个匹配的<img>元素打包, 即添加父元素<a>
			$(this).wrap('<a data-fancybox href=" ' + videoPath + ' "> </a>');
		});
		
		//TODO：支持html5 video

		if($('#layout-post').length) {
			$('[data-fancybox="gallery"]').fancybox({
				loop: true,
				buttons: [
					"zoom",
					"share",
					"slideShow",
					"fullScreen",
					//"download",
					"thumbs",
					"close"
				],
				protect: true
			});
		}
	})();
</script>
		</main>

		<!--footer-->
		<footer>
	<div id="navigation-show">
		<ul id="global-nav">
	
		<li class="menu-home">
			<a href="/" class="menu-item-home" target="_blank">主页</a>
		</li>
		
	
		<li class="menu-archive">
			<a href="/archives" class="menu-item-archive" target="_blank">归档</a>
		</li>
		
	
		<li class="menu-categories">
			<a href="/categories" class="menu-item-categories" target="_blank">分类</a>
		</li>
		
	
		<li class="menu-tags">
			<a href="/tags" class="menu-item-tags" target="_blank">标签</a>
		</li>
		
	
		<li class="menu-about">
			<a href="/about" class="menu-item-about" target="_blank">关于</a>
		</li>
		
	

	
		<li class="menu-search">
			<a href="javascript:;" class="popup-trigger">搜索</a>
		</li>
	
</ul>
	</div>

	<div class="copyright">
		<p>
		<a href="http://www.beian.miit.gov.cn/" target="_blank" rel="noopener">鲁ICP备16042410号</a>
			 
				&copy;2017 - 2022, content by SongqianLi. All Rights Reserved.
			
			
				<a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> Theme <a href="https://github.com/Sariay/hexo-theme-Annie" title="Annie" target="_blank" rel="noopener">Annie</a> by Sariay.
			
		</p>
		<p>
			

	<!-- busuanzi -->
	<!-- busuanzi -->



			<a href="javascript:zh_tran('s');" class="zh_click" id="zh_click_s">简体</a> 
			<a href="javascript:zh_tran('t');" class="zh_click" id="zh_click_t">繁體</a>				
		</p>
	</div>		
</footer>
		

<!-- love effect -->


<!-- back to top -->

	<div id="totop">
	<span class="icon-circle-up"></span>
</div>




<!-- leancloud -->


	<!-- leancloud -->
	<!--
	时间：2018-11-27
	描述：
		文章访问量：visitors
		文章喜欢量：likes	
		文章排行榜：topNPost
		其他得说明：
			01-Cookie相关的函数 
				https://blog.csdn.net/somehow1002/article/details/78511541（Author：somehow1002）
			02-visitors相关的函数 
				https://blog.csdn.net/u013553529/article/details/63357382（Author：爱博客大伯）
				https://notes.doublemine.me/2015-10-21-为NexT主题添加文章阅读量统计功能.html（Author：夏末）
			03-topNPost相关的函数
				https://hoxis.github.io/hexo-next-read-rank.html（Author：hoxis）
			04-likes相关的函数，
				参考了01 & 02进行简单的设计与实现
-->


  
<script src="/plugin/leancloud/av-min.js"></script>
<script src="/js/leancloud-count.js"></script>


	

  

	<!--
	时间：2018-10-3
	描述：
		插件名称：hexo-generator-search-zip
		插件来源: https://github.com/SuperKieran/hexo-generator-search-zip
		代码参考：https://github.com/SuperKieran/TKL/blob/master/layout/_partial/search.ejs(Include: js & css)	
-->
<div class="popup search-popup local-search-popup scrollbar" >
	<div class="local-search-container">
		<span class="popup-btn-close">
      		ESC
   		</span>
		<div class="local-search-header">
			<div class="input-prompt">				
			</div>
			<input autocomplete="off" placeholder="Search..." type="text" id="local-search-input">
		</div>
		<div class="local-search-body">
			<div id="local-search-output"></div>
		</div>
		<div class="local-search-footer">
			<div class="topN-post">				
				

   
	<div id="topN">
		<div class="topN-title" data-title= "热门文章"></div> 
	</div>
	
    <script>
        var limitCount = 10;
        if( $('#topN').length ){
            setTimeout(function() {
                topNPost(limitCount);
			}, 3000);
        }
    </script>
   
								
			</div>
		</div>
	</div>
</div>


<script src="/plugin/search/ziploader.js"></script>
<script src="/js/search.js"></script>


<script type="text/javascript">
	var search_path = 'search.json',
		zip_Path = '/search.zip',
		version_Path = '/searchVersion.txt',
		input_Trigger = 'auto',
		top_N = '2';

	themeLocalSearch({
		search_path, 
		zip_Path, 
		version_Path, 
		input_Trigger, 
		top_N
	});
</script>



<script src="/plugin/chinese/chinese.js"></script>
<script src="/plugin/imagelazyloader/yall.min.js"></script>
<script src="/plugin/imageloaded/imagesloaded.pkgd.min.js"></script>
<script src="/plugin/resizediv/resizediv.js"></script>
<script src="/js/main.js"></script>

	</body>	
</html>